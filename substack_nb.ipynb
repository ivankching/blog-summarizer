{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0773482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from substack_api import Post, Newsletter, User\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcd9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('post_content')\n",
    "\n",
    "for item in directory.iterdir():\n",
    "    if item.is_file() or item.is_symlink():\n",
    "        item.unlink()\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d98e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"ivankching\"\n",
    "date_str = \"2025-10-19T00:00:00.000Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07c3d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(username=ivankching)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = User(username)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0cc56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publication_id': 1174659,\n",
       "  'publication_name': 'Ahead of AI',\n",
       "  'domain': 'magazine.sebastianraschka.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 4083837,\n",
       "  'publication_name': 'The AI Engineer',\n",
       "  'domain': 'www.aimlengineer.io',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 1560026,\n",
       "  'publication_name': 'Andrej’s Substack',\n",
       "  'domain': 'karpathy.substack.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 289327,\n",
       "  'publication_name': 'Deep Learning Weekly',\n",
       "  'domain': 'www.deeplearningweekly.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 48041,\n",
       "  'publication_name': 'Gwern.net Newsletter',\n",
       "  'domain': 'gwern.substack.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 18908,\n",
       "  'publication_name': 'Monomythical',\n",
       "  'domain': 'nayafia.substack.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 1178062,\n",
       "  'publication_name': 'NLP News',\n",
       "  'domain': 'newsletter.ruder.io',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 35345,\n",
       "  'publication_name': 'Noahpinion',\n",
       "  'domain': 'www.noahpinion.blog',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 737237,\n",
       "  'publication_name': 'The Substack Post',\n",
       "  'domain': 'post.substack.com',\n",
       "  'membership_state': 'free_signup'},\n",
       " {'publication_id': 1199196,\n",
       "  'publication_name': 'Sustainability by numbers',\n",
       "  'domain': 'www.sustainabilitybynumbers.com',\n",
       "  'membership_state': 'free_signup'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.get_subscriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aedf9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletters = {}\n",
    "for d in user.get_subscriptions():\n",
    "    newsletters[d[\"publication_name\"]] = Newsletter(f\"https://{d[\"domain\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a6333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter = newsletters[\"Sustainability by numbers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdace46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = newsletter.get_posts(sorting='new', limit=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a254011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Post(url=https://www.sustainabilitybynumbers.com/p/iea-current-policies-scenario),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/global-carbon-emissions-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/amazon-deforestation-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/artificial-intelligence-could-dramatically),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/usa-electricity-growth),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/eliminating-contrails),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/food-projections-2025)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71f6f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-09-22T05:45:59.562Z'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = posts[-1]\n",
    "post.get_metadata()[\"post_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644cce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audience': 'everyone',\n",
       " 'audience_before_archived': None,\n",
       " 'canonical_url': 'https://www.sustainabilitybynumbers.com/p/food-projections-2025',\n",
       " 'default_comment_sort': None,\n",
       " 'editor_v2': False,\n",
       " 'exempt_from_archive_paywall': False,\n",
       " 'free_unlock_required': False,\n",
       " 'id': 174220389,\n",
       " 'podcast_art_url': None,\n",
       " 'podcast_duration': None,\n",
       " 'podcast_preview_upload_id': None,\n",
       " 'podcast_upload_id': None,\n",
       " 'podcast_url': None,\n",
       " 'post_date': '2025-09-22T05:45:59.562Z',\n",
       " 'updated_at': '2025-09-22T05:46:20.278Z',\n",
       " 'publication_id': 1199196,\n",
       " 'search_engine_description': None,\n",
       " 'search_engine_title': None,\n",
       " 'section_id': None,\n",
       " 'should_send_free_preview': False,\n",
       " 'show_guest_bios': True,\n",
       " 'slug': 'food-projections-2025',\n",
       " 'social_title': 'The world is on track for record harvests this year',\n",
       " 'subtitle': 'What do the latest projections expect for global food production and yields of different crops?',\n",
       " 'teaser_post_eligible': True,\n",
       " 'title': 'The world is on track for record harvests this year',\n",
       " 'type': 'newsletter',\n",
       " 'video_upload_id': None,\n",
       " 'write_comment_permissions': 'everyone',\n",
       " 'meter_type': 'none',\n",
       " 'live_stream_id': None,\n",
       " 'is_published': True,\n",
       " 'restacks': 26,\n",
       " 'reactions': {'❤': 199},\n",
       " 'top_exclusions': [],\n",
       " 'pins': [],\n",
       " 'section_pins': [],\n",
       " 'has_shareable_clips': False,\n",
       " 'previous_post_slug': 'clearing-the-air-published-uk',\n",
       " 'next_post_slug': 'eliminating-contrails',\n",
       " 'cover_image': 'https://substack-post-media.s3.amazonaws.com/public/images/c6fac9d1-cefc-434e-9f3b-1cd8fca67daf_1280x853.jpeg',\n",
       " 'cover_image_is_square': False,\n",
       " 'cover_image_is_explicit': False,\n",
       " 'videoUpload': None,\n",
       " 'podcastFields': {'post_id': 174220389,\n",
       "  'podcast_episode_number': None,\n",
       "  'podcast_season_number': None,\n",
       "  'podcast_episode_type': None,\n",
       "  'should_syndicate_to_other_feed': None,\n",
       "  'syndicate_to_section_id': None,\n",
       "  'hide_from_feed': False,\n",
       "  'free_podcast_url': None,\n",
       "  'free_podcast_duration': None},\n",
       " 'podcastUpload': None,\n",
       " 'podcastPreviewUpload': None,\n",
       " 'voiceover_upload_id': None,\n",
       " 'voiceoverUpload': None,\n",
       " 'has_voiceover': False,\n",
       " 'description': 'What do the latest projections expect for global food production and yields of different crops?',\n",
       " 'body_html': '<p>It’s not uncommon for people to tell me that global food production is already collapsing due to climate change. They are then surprised to hear that we typically hit record harvests year after year (even as things get hotter).<a class=\"footnote-anchor\" data-component-name=\"FootnoteAnchorToDOM\" id=\"footnote-anchor-1\" href=\"#footnote-1\" target=\"_self\">1</a></p><p>But there are large and genuine risks of climate change to agriculture — I’ve <a href=\"https://ourworldindata.org/crop-yields-climate-impact\">written about this</a> a lot, and it is probably my biggest concern when it comes to climate impacts — and there’s no guarantee that rising productivity continues.</p><p>The United States Department of Agriculture (USDA) <a href=\"https://apps.fas.usda.gov/psdonline/app/index.html\">tracks agricultural conditions</a> across the world and publishes monthly updates on its outlook for production and yields for the year. I check this often to see how things are looking.</p><p>I posted an update on this last year, so here is the 2025 version.</p><p>The data I’m relying on for this summary is the USDA projections for the year based on <a href=\"https://apps.fas.usda.gov/psdonline/circulars/production.pdf\">its latest update</a> (September 2025).</p><p>Note: These are <em>projections</em> based on the latest assessment of growing conditions and planting areas. For various reasons, this could change in the next few months.</p><div><hr></div><h2><strong>Corn, wheat, soybeans and rice are on track for record harvests</strong></h2><p>Here’s the total amount of staple crops the world has produced since 1960. The last year — 2025 — is the USDA’s latest projection.</p><p>Most crops, with the exception of sorghum and millet, have seen steady increases over the past 60 years, and that trend is expected to continue this year.</p><p>Corn (maize) and wheat, in particular, have seen large increases this year. Soybeans are also expected to see a record. For rice, the rise is very small — basically the same output as last year (which was also a record).</p><p>Sorghum and millet — lesser-known but important staple crops <a href=\"https://ourworldindata.org/explorers/global-food?Food=Millet&amp;Metric=Production&amp;Per+capita=false&amp;country=OWID_WRL~USA~CHN~IND~BRA~GBR\">in the tropics</a> — continue with their regular pattern, fluctuating up and down without much sustained growth at all. This is concerning for food security, especially across Sub-Saharan Africa.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!9kUo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!9kUo!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 424w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 848w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 1272w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!9kUo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png\" width=\"1456\" height=\"1034\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1034,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!9kUo!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 424w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 848w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 1272w, https://substackcdn.com/image/fetch/$s_!9kUo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24a7d693-d9d0-4e6c-8985-c06211581c20_1600x1136.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>In the chart below, I’ve zoomed in on production figures since 2000 to see the recent data more clearly.</p><p>Again, you see the very large jump for corn in 2025; a reasonable jump for wheat, but much smaller increases for soybean and rice.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!Wub6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wub6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 424w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 848w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 1272w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!Wub6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png\" width=\"1456\" height=\"1023\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1023,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wub6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 424w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 848w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 1272w, https://substackcdn.com/image/fetch/$s_!Wub6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F941d3b0d-d775-42f1-b5c2-7539b28f8c33_1600x1124.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><div><hr></div><h2><strong>Global yields of staple crops are also expected to reach an all-time high</strong></h2><p>It’s also important to look at crop <em>yields</em>. Producing more food from higher yields means using less land for farming (and the benefits that come with it), and it also means better returns for farmers.</p><p>Corn, wheat, soybeans, and rice are all expected to see record yields this year. You can see this in the chart below.</p><p>Again, the jump for corn and wheat is fairly substantial. However, the rise in soybeans and rice is also more noticeable this time. Their increase in production was extremely marginal, so the fact that yields have increased quite a bit means that the <em>area</em> of soybean and rice crops planted is down from the previous year.</p><p>Again, you can see how poor the yields for sorghum and millet are. These are crops that have not received the same R&amp;D investment as others, and it shows.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!qe6O!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!qe6O!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 424w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 848w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 1272w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!qe6O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png\" width=\"1456\" height=\"1161\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/40900507-426d-4750-88d4-b76339988869_1600x1276.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1161,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!qe6O!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 424w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 848w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 1272w, https://substackcdn.com/image/fetch/$s_!qe6O!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F40900507-426d-4750-88d4-b76339988869_1600x1276.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Here’s the data, just from the year 2000, which makes the recent changes easier to see.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!9W1K!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!9W1K!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 424w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 848w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 1272w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!9W1K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png\" width=\"1456\" height=\"1082\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1082,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!9W1K!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 424w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 848w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 1272w, https://substackcdn.com/image/fetch/$s_!9W1K!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9215fa81-9185-4eb9-9ebe-944504ddb28e_1600x1189.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><div><hr></div><h2><strong>What’s happening with non-staple crops: oils, cotton and coffee?</strong></h2><p>What about some other key crops that aren’t cereal or pulse staples?</p><p>Here — as you might expect for a wide range of crops — the picture is a bit more mixed. Below, I’ve shown the production figures for some oilseed crops, such as sugar, coffee, and cotton.</p><p>Rapeseed, palm oil, and coffee are all on track for record harvests. Sunflowerseed, cotton, and sugar are not.</p><p>As you can see, production figures fluctuate quite a bit from year to year, partly due to changes in weather conditions (i.e. supply) and changes in the market (i.e. demand).</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!qO5A!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!qO5A!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 424w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 848w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 1272w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!qO5A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png\" width=\"1456\" height=\"1053\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1053,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!qO5A!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 424w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 848w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 1272w, https://substackcdn.com/image/fetch/$s_!qO5A!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4210233b-4d35-4229-b25c-5d7b2dd120e6_1600x1157.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Again, these are current projections to the end of the year, and subject to change. But the current data points towards strong agricultural output this year.</p><p>This summary of <em>global</em> food production obviously doesn’t reflect farming conditions and output <em>everywhere</em>. The USDA <a href=\"https://apps.fas.usda.gov/psdonline/circulars/production.pdf\">provides more in-depth coverage</a> of countries or regions where production is up and where it’s down from previous years.</p><p>Large disruptions in national or regional production can occur without major changes to <em>global</em> production. This is one reason why a <em>global</em> interconnected food system can be much more resilient than local ones. Every year, some farmers get extremely poor harvests. But these losses can often be balanced out with surpluses elsewhere. This is very different from our food systems of the past, when a bad harvest inevitably meant hunger.</p><div><hr></div><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://www.sustainabilitybynumbers.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://www.sustainabilitybynumbers.com/subscribe?\"><span>Subscribe now</span></a></p><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://www.penguin.co.uk/books/462676/clearing-the-air-by-ritchie-hannah/9781784745745&quot;,&quot;text&quot;:&quot;My latest book is out&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://www.penguin.co.uk/books/462676/clearing-the-air-by-ritchie-hannah/9781784745745\"><span>My latest book is out</span></a></p><p></p><div class=\"footnote\" data-component-name=\"FootnoteToDOM\"><a id=\"footnote-1\" href=\"#footnote-anchor-1\" class=\"footnote-number\" contenteditable=\"false\" target=\"_self\">1</a><div class=\"footnote-content\"><p>This is because even as increased temperatures have negative impacts on some crops, other improvements and enhancements in crop production have outpaced many of those impacts.</p><p></p></div></div>',\n",
       " 'truncated_body_text': 'It’s not uncommon for people to tell me that global food production is already collapsing due to climate change. They are then surprised to hear that we typically hit record harvests year after year (even as things get hotter).',\n",
       " 'wordcount': 769,\n",
       " 'postTags': [],\n",
       " 'postCountryBlocks': [],\n",
       " 'headlineTest': None,\n",
       " 'coverImagePalette': {'Vibrant': {'rgb': [136, 183, 74], 'population': 402},\n",
       "  'DarkVibrant': {'rgb': [64, 97, 45], 'population': 367},\n",
       "  'LightVibrant': {'rgb': [196, 215, 98], 'population': 248},\n",
       "  'Muted': {'rgb': [136, 169, 76], 'population': 347},\n",
       "  'DarkMuted': {'rgb': [86, 97, 54], 'population': 22},\n",
       "  'LightMuted': {'rgb': [166, 186, 110], 'population': 4}},\n",
       " 'publishedBylines': [{'id': 10269516,\n",
       "   'name': 'Hannah Ritchie',\n",
       "   'handle': 'hannahritchie',\n",
       "   'previous_name': None,\n",
       "   'photo_url': 'https://substack-post-media.s3.amazonaws.com/public/images/4c2e12f4-9a9f-4bb7-96c9-f91bc5f60840_680x680.jpeg',\n",
       "   'bio': None,\n",
       "   'profile_set_up_at': '2022-11-18T09:25:42.905Z',\n",
       "   'reader_installed_at': '2022-11-20T09:05:30.005Z',\n",
       "   'publicationUsers': [{'id': 1153597,\n",
       "     'user_id': 10269516,\n",
       "     'publication_id': 1199196,\n",
       "     'role': 'admin',\n",
       "     'public': True,\n",
       "     'is_primary': True,\n",
       "     'publication': {'id': 1199196,\n",
       "      'name': 'Sustainability by numbers',\n",
       "      'subdomain': 'hannahritchie',\n",
       "      'custom_domain': 'www.sustainabilitybynumbers.com',\n",
       "      'custom_domain_optional': False,\n",
       "      'hero_text': 'Using data and research to understand what really makes a difference',\n",
       "      'logo_url': 'https://substack-post-media.s3.amazonaws.com/public/images/0b3f5948-e0e4-4164-975a-d4b800dedf19_1080x1080.png',\n",
       "      'author_id': 10269516,\n",
       "      'primary_user_id': 10269516,\n",
       "      'theme_var_background_pop': '#99A2F1',\n",
       "      'created_at': '2022-11-18T09:30:27.358Z',\n",
       "      'email_from_name': None,\n",
       "      'copyright': 'Hannah Ritchie',\n",
       "      'founding_plan_name': None,\n",
       "      'community_enabled': True,\n",
       "      'invite_only': False,\n",
       "      'payments_state': 'disabled',\n",
       "      'language': None,\n",
       "      'explicit': False,\n",
       "      'homepage_type': 'newspaper',\n",
       "      'is_personal_mode': False}}],\n",
       "   'twitter_screen_name': '_HannahRitchie',\n",
       "   'is_guest': False,\n",
       "   'bestseller_tier': None,\n",
       "   'status': {'bestsellerTier': None,\n",
       "    'subscriberTier': None,\n",
       "    'leaderboard': None,\n",
       "    'vip': False,\n",
       "    'badge': None,\n",
       "    'paidPublicationIds': [],\n",
       "    'subscriber': None}}],\n",
       " 'reaction': None,\n",
       " 'reaction_count': 199,\n",
       " 'comment_count': 121,\n",
       " 'child_comment_count': 23,\n",
       " 'audio_items': [{'post_id': 174220389,\n",
       "   'voice_id': 'en-GB-AdaMultilingualNeural',\n",
       "   'audio_url': 'https://substack-video.s3.amazonaws.com/video_upload/post/174220389/tts/e8facfd9-f074-4a82-9cd7-8d25d800b2c1/en-GB-AdaMultilingualNeural.mp3',\n",
       "   'type': 'tts',\n",
       "   'status': 'completed'}],\n",
       " 'is_geoblocked': False,\n",
       " 'hasCashtag': False,\n",
       " 'unlockedWithIP': False,\n",
       " 'themeVariables': {'color_theme_bg_pop': '#51b4e9',\n",
       "  'background_pop': '#51b4e9',\n",
       "  'color_theme_bg_web': '#f5f5f5',\n",
       "  'cover_bg_color': '#f5f5f5',\n",
       "  'cover_bg_color_secondary': '#e6e6e6',\n",
       "  'background_pop_darken': '#3aaae6',\n",
       "  'print_on_pop': '#ffffff',\n",
       "  'color_theme_bg_pop_darken': '#3aaae6',\n",
       "  'color_theme_print_on_pop': '#ffffff',\n",
       "  'color_theme_bg_pop_20': 'rgba(81, 180, 233, 0.2)',\n",
       "  'color_theme_bg_pop_30': 'rgba(81, 180, 233, 0.3)',\n",
       "  'border_subtle': 'rgba(196, 196, 196, 0.5)',\n",
       "  'background_subtle': 'rgba(229, 244, 252, 0.4)',\n",
       "  'print_pop': '#51b4e9',\n",
       "  'color_theme_accent': '#51b4e9',\n",
       "  'cover_print_primary': '#363737',\n",
       "  'cover_print_secondary': '#757575',\n",
       "  'cover_print_tertiary': '#b6b6b6',\n",
       "  'cover_border_color': '#51b4e9',\n",
       "  'font_family_headings_preset': 'Lora,sans-serif',\n",
       "  'font_weight_headings_preset': 600,\n",
       "  'font_family_body_preset': \"'Roboto Slab',sans-serif\",\n",
       "  'font_weight_body_preset': 400,\n",
       "  'font_preset_heading': 'fancy_serif',\n",
       "  'font_preset_body': 'slab',\n",
       "  'home_hero': 'newspaper',\n",
       "  'home_posts': 'list',\n",
       "  'web_bg_color': '#f5f5f5',\n",
       "  'background_contrast_1': '#e6e6e6',\n",
       "  'color_theme_bg_contrast_1': '#e6e6e6',\n",
       "  'background_contrast_2': '#d4d4d4',\n",
       "  'color_theme_bg_contrast_2': '#d4d4d4',\n",
       "  'background_contrast_3': '#b0b0b0',\n",
       "  'color_theme_bg_contrast_3': '#b0b0b0',\n",
       "  'background_contrast_4': '#8d8d8d',\n",
       "  'color_theme_bg_contrast_4': '#8d8d8d',\n",
       "  'background_contrast_5': '#4d4d4d',\n",
       "  'color_theme_bg_contrast_5': '#4d4d4d',\n",
       "  'color_theme_bg_elevated': '#f5f5f5',\n",
       "  'color_theme_bg_elevated_secondary': '#e6e6e6',\n",
       "  'color_theme_bg_elevated_tertiary': '#d4d4d4',\n",
       "  'color_theme_detail': '#dddddd',\n",
       "  'background_contrast_pop': 'rgba(81, 180, 233, 0.4)',\n",
       "  'color_theme_bg_contrast_pop': 'rgba(81, 180, 233, 0.4)',\n",
       "  'input_background': '#f6f6f6',\n",
       "  'cover_input_background': '#f6f6f6',\n",
       "  'tooltip_background': '#181818',\n",
       "  'web_bg_color_h': '0',\n",
       "  'web_bg_color_s': '0%',\n",
       "  'web_bg_color_l': '96.07843137254902%',\n",
       "  'print_on_web_bg_color': '#363737',\n",
       "  'print_secondary_on_web_bg_color': '#828383',\n",
       "  'selected_comment_background_color': '#f4f0ea',\n",
       "  'background_pop_rgb': '81, 180, 233',\n",
       "  'background_pop_rgb_pc': '81 180 233',\n",
       "  'color_theme_bg_pop_rgb': '81, 180, 233',\n",
       "  'color_theme_bg_pop_rgb_pc': '81 180 233',\n",
       "  'color_theme_accent_rgb': '81, 180, 233',\n",
       "  'color_theme_accent_rgb_pc': '81 180 233'},\n",
       " 'comments': [{'id': 158577376,\n",
       "   'body': 'Cool! Hey I wonder why potato is rarely included in these. At some 400 MT, it is a far more important source of calories than Sorghum or Millet, though not a cereal. ',\n",
       "   'body_json': {'type': 'doc',\n",
       "    'attrs': {'schemaVersion': 'v1'},\n",
       "    'content': [{'type': 'paragraph',\n",
       "      'content': [{'type': 'text',\n",
       "        'text': 'Cool! Hey I wonder why potato is rarely included in these. At some 400 MT, it is a far more important source of calories than Sorghum or Millet, though not a cereal.'}]}]},\n",
       "   'publication_id': 1199196,\n",
       "   'post_id': 174220389,\n",
       "   'user_id': 13535611,\n",
       "   'ancestor_path': '',\n",
       "   'type': 'comment',\n",
       "   'deleted': False,\n",
       "   'date': '2025-09-22T06:23:56.360Z',\n",
       "   'edited_at': None,\n",
       "   'status': 'published',\n",
       "   'pinned_by_user_id': None,\n",
       "   'restacks': 0,\n",
       "   'name': 'JBjb4321',\n",
       "   'photo_url': None,\n",
       "   'handle': 'joannesberque234322',\n",
       "   'reactor_names': [],\n",
       "   'reaction': None,\n",
       "   'reactions': {'❤': 11},\n",
       "   'reaction_count': 11,\n",
       "   'children': [],\n",
       "   'bans': [],\n",
       "   'suppressed': False,\n",
       "   'user_banned': False,\n",
       "   'user_banned_for_comment': False,\n",
       "   'user_slug': 'joannesberque234322',\n",
       "   'metadata': {'is_author': False,\n",
       "    'membership_state': 'free_signup',\n",
       "    'eligibleForGift': False},\n",
       "   'country_blocks': [],\n",
       "   'user_bestseller_tier': None,\n",
       "   'can_dm': True,\n",
       "   'userStatus': {'bestsellerTier': None,\n",
       "    'subscriberTier': 1,\n",
       "    'leaderboard': None,\n",
       "    'vip': False,\n",
       "    'badge': {'type': 'subscriber', 'tier': 1, 'accent_colors': None},\n",
       "    'subscriber': None},\n",
       "   'score': 12,\n",
       "   'children_count': 2,\n",
       "   'reported_by_user': False,\n",
       "   'restacked': False,\n",
       "   'childrenSummary': '4 replies'},\n",
       "  {'id': 158628450,\n",
       "   'body': \"i would love to see the productivity rather than just the size of the harvest. the thought leapt out at me when i saw the chart for Palm oil. common knowledge (i.e. I'm not going to look up sources at this point) say that the increase in palm oil production comes at the cost of hectares of primary rainforest. there's nothing good in that and it would useful to see if there is any increase in the production per hectare and whether that increase plays out in the same way across this whole dataset.\",\n",
       "   'body_json': {'type': 'doc',\n",
       "    'attrs': {'schemaVersion': 'v1'},\n",
       "    'content': [{'type': 'paragraph',\n",
       "      'content': [{'type': 'text',\n",
       "        'text': \"i would love to see the productivity rather than just the size of the harvest. the thought leapt out at me when i saw the chart for Palm oil. common knowledge (i.e. I'm not going to look up sources at this point) say that the increase in palm oil production comes at the cost of hectares of primary rainforest. there's nothing good in that and it would useful to see if there is any increase in the production per hectare and whether that increase plays out in the same way across this whole dataset.\"}]}]},\n",
       "   'publication_id': 1199196,\n",
       "   'post_id': 174220389,\n",
       "   'user_id': 10572880,\n",
       "   'ancestor_path': '',\n",
       "   'type': 'comment',\n",
       "   'deleted': False,\n",
       "   'date': '2025-09-22T12:13:14.264Z',\n",
       "   'edited_at': None,\n",
       "   'status': 'published',\n",
       "   'pinned_by_user_id': None,\n",
       "   'restacks': 0,\n",
       "   'name': 'Adam Hardy',\n",
       "   'photo_url': None,\n",
       "   'handle': None,\n",
       "   'reactor_names': [],\n",
       "   'reaction': None,\n",
       "   'reactions': {'❤': 7},\n",
       "   'reaction_count': 7,\n",
       "   'children': [],\n",
       "   'bans': [],\n",
       "   'suppressed': False,\n",
       "   'user_banned': False,\n",
       "   'user_banned_for_comment': False,\n",
       "   'user_slug': '10572880-adam-hardy',\n",
       "   'metadata': {'is_author': False,\n",
       "    'membership_state': None,\n",
       "    'eligibleForGift': False},\n",
       "   'country_blocks': [],\n",
       "   'user_bestseller_tier': None,\n",
       "   'can_dm': True,\n",
       "   'userStatus': {'bestsellerTier': None,\n",
       "    'subscriberTier': None,\n",
       "    'leaderboard': None,\n",
       "    'vip': False,\n",
       "    'badge': None,\n",
       "    'subscriber': None},\n",
       "   'score': 8,\n",
       "   'children_count': 1,\n",
       "   'reported_by_user': False,\n",
       "   'restacked': False,\n",
       "   'childrenSummary': '4 replies'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da18caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from substack import download_substack_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22105d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Added newsletter: Ahead of AI\n",
      "INFO:root:Added newsletter: The AI Engineer\n",
      "INFO:root:Added newsletter: Andrej’s Substack\n",
      "INFO:root:Added newsletter: Deep Learning Weekly\n",
      "INFO:root:Added newsletter: Gwern.net Newsletter\n",
      "INFO:root:Added newsletter: Monomythical\n",
      "INFO:root:Added newsletter: NLP News\n",
      "INFO:root:Added newsletter: Noahpinion\n",
      "INFO:root:Added newsletter: The Substack Post\n",
      "INFO:root:Added newsletter: Sustainability by numbers\n",
      "INFO:root:Added post beyond-standard-llms from newsletter Ahead of AI\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:Added post deep-learning-weekly-issue-431 from newsletter Deep Learning Weekly\n",
      "INFO:root:Added post deep-learning-weekly-issue-430 from newsletter Deep Learning Weekly\n",
      "INFO:root:Added post deep-learning-weekly-issue-429 from newsletter Deep Learning Weekly\n",
      "INFO:root:Added post deep-learning-weekly-issue-428 from newsletter Deep Learning Weekly\n",
      "INFO:root:Added post deep-learning-weekly-issue-427 from newsletter Deep Learning Weekly\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "INFO:root:Added post at-least-five-interesting-things-5b8 from newsletter Noahpinion\n",
      "INFO:root:Added post the-economics-theory-that-could-have from newsletter Noahpinion\n",
      "INFO:root:Added post the-future-of-war-is-the-future-of from newsletter Noahpinion\n",
      "INFO:root:Added post housing-is-at-the-heart-of-americas from newsletter Noahpinion\n",
      "INFO:root:Added post chinas-people-are-on-a-treadmill from newsletter Noahpinion\n",
      "INFO:root:Added post eurocope from newsletter Noahpinion\n",
      "INFO:root:Added post zohrans-real-problems-arent-what from newsletter Noahpinion\n",
      "INFO:root:Added post i-want-the-japanese-future-back from newsletter Noahpinion\n",
      "INFO:root:Added post at-least-five-interesting-things-824 from newsletter Noahpinion\n",
      "INFO:root:Added post the-internet-wants-to-be-fragmented-6b5 from newsletter Noahpinion\n",
      "INFO:root:Added post im-a-weeb-for-ireland from newsletter Noahpinion\n",
      "INFO:root:Added post the-great-world-war-2-afterparty from newsletter Noahpinion\n",
      "INFO:root:Added post the-giant-basket-case-countries from newsletter Noahpinion\n",
      "INFO:root:Added post economic-ideas-for-takaichi-sanae from newsletter Noahpinion\n",
      "INFO:root:Added post bring-back-liberal-nationalism from newsletter Noahpinion\n",
      "INFO:root:Added post our-age-of-kings from newsletter Noahpinion\n",
      "INFO:root:Added post trumps-energy-policy-is-incoherent from newsletter Noahpinion\n",
      "INFO:root:Added post should-we-worry-about-ais-circular from newsletter Noahpinion\n",
      "INFO:root:Added post after-trump-the-deluge from newsletter Noahpinion\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n",
      "ERROR:root:Error downloading posts from newsletter The Substack Post: 404 Client Error: Not Found for url: https://itscharlibb.substack.com/api/v1/posts/178738131\n",
      "INFO:root:{'status': 'error', 'message': '404 Client Error: Not Found for url: https://itscharlibb.substack.com/api/v1/posts/178738131'}\n",
      "INFO:root:Added post iea-current-policies-scenario from newsletter Sustainability by numbers\n",
      "INFO:root:Added post global-carbon-emissions-2025 from newsletter Sustainability by numbers\n",
      "INFO:root:Added post amazon-deforestation-2025 from newsletter Sustainability by numbers\n",
      "INFO:root:Added post artificial-intelligence-could-dramatically from newsletter Sustainability by numbers\n",
      "INFO:root:Added post usa-electricity-growth from newsletter Sustainability by numbers\n",
      "INFO:root:{'status': 'success', 'message': 'Posts downloaded successfully'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'success', 'message': 'Posts downloaded successfully'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_substack_posts(username, date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d9ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter = newsletters[\"Ahead of AI\"]\n",
    "posts = newsletter.get_posts(sorting='new', limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d184655",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = posts[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48068b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_date = datetime.strptime(post.get_metadata()[\"post_date\"], \"%Y-%m-%dT%H:%M:%S.%f%z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9ce31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 5, 12, 11, 2, 46, 703000, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89de32a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 10, 19, 0, 0, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = datetime.strptime(date_str,  \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b0c7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html_reader import batch_convert, clean_and_convert, clean_whitespaces_markdown\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8a50459",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = post.get_metadata()\n",
    "html = metadata[\"body_html\"]\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1500673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<header><h1>How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?</h1><p>Discussing the Latest Model Releases and AI Research in April 2024</p></header>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = soup.new_tag('header')\n",
    "h1 = soup.new_tag('h1')\n",
    "h1.string = metadata[\"title\"]\n",
    "h2 = soup.new_tag('p')\n",
    "h2.string = metadata[\"subtitle\"]\n",
    "header.append(h1)\n",
    "header.append(h2)\n",
    "soup.insert(0, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bc18ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<header><h1>How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?</h1><p>Discussing the Latest Model Releases and AI Research in April 2024</p></header><p>April 2024, what a month! My birthday, a <a href=\"https://www.amazon.com/Machine-Learning-AI-Essential-Questions/dp/1718503768\">new book release</a>, spring is finally here, and four major open LLM releases: Mixtral, Meta AI's Llama 3, Microsoft's Phi-3, and Apple's OpenELM.</p><p>This article reviews and discusses all four major transformer-based LLM model releases that have been happening in the last few weeks, followed by new research on reinforcement learning with human feedback methods for instruction finetuning using PPO and DPO algorithms.</p><p>1. How Good are Mixtral, Llama 3, and Phi-3?</p><p>2. OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</p><p>3. Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</p><p>4. Other Interesting Research Papers In April</p><h1>1. Mixtral, Llama 3, and Phi-3: What's New?</h1><p>First, let's start with the most prominent topic: the new major LLM releases this month. This section will briefly cover Mixtral, Llama 3, and Phi-3, which have been accompanied by short blog posts or short technical papers. The next section will cover Apple's OpenELM in a bit more detail, which thankfully comes with a research paper that shares lots of interesting details.</p><h2><strong>1.1 Mixtral 8x22B: Larger models are better!</strong></h2><p><a href=\"https://mistral.ai/news/mixtral-8x22b/\">Mixtral 8x22B</a> is the latest mixture-of-experts (MoE) model by Mistral AI, which has been released under a permissive Apache 2.0 open-source license.</p><p>Similar to the Mixtral 8x7B released in January 2024, the key idea behind this model is to replace each feed-forward module in a transformer architecture with 8 expert layers. It's going to be a relatively long article, so I am skipping the MoE explanations, but if you are interested, the Mixtral 8x7B section in an article I shared a few months ago is a bit more detailed:</p><div class=\"digest-post-embed\" data-attrs='{\"nodeId\":\"70cc9ff2-cfe5-4acf-ad23-4c6f03bf3788\",\"caption\":\"2023 was the year when the potential and complexity of Large Language Models (LLMs) were growing rapidly. Looking at the open source and research advancements in 2024, it seems we are going to a welcome phase of making models better (and smaller) without increasing their size.\",\"cta\":null,\"showBylines\":true,\"size\":\"sm\",\"isEditorNode\":true,\"title\":\"Research Papers in Jan 2024: Model Merging, Mixtures of Experts, and Towards Smaller LLMs\",\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"bio\":\"Sebastian is a machine learning and AI researcher with over a decade of experience in the field. He is very passionate about explaining complex technical concepts and \\\"taking the magic out of AI.\\\"\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"is_guest\":false,\"bestseller_tier\":null}],\"post_date\":\"2024-02-03T11:55:32.219Z\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/f0f815fd-f34a-4595-8009-1e1e3e5fa3bd_1302x894.png\",\"cover_image_alt\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/research-papers-in-january-2024\",\"section_name\":null,\"video_upload_id\":null,\"id\":141130005,\"type\":\"newsletter\",\"reaction_count\":163,\"comment_count\":15,\"publication_id\":null,\"publication_name\":\"Ahead of AI\",\"publication_logo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4dcbe6f-2617-404f-8368-9bc428272016_1280x1280.png\",\"belowTheFold\":true}'></div><p>The perhaps most interesting plot from the<a href=\"https://mistral.ai/news/mixtral-8x22b/\"> Mixtral blog post</a>, which compares Mixtral 8x22B to several LLMs on two axes: modeling performance on the popular <a href=\"https://arxiv.org/abs/2009.03300\">Measuring Massive Multitask Language Understanding</a> (MMLU) benchmark and active parameters (related to computational resource requirements).</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!L-zh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!L-zh!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 424w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 848w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 1272w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":820,\"width\":1414,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"820\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!L-zh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!L-zh!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 424w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 848w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 1272w, https://substackcdn.com/image/fetch/$s_!L-zh!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01cfd078-5792-4ea8-833f-4ecd43a2771a_1414x820.png 1456w\" width=\"1414\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>A comparison between Mixtral 8x22B and other LLMs. (Annotated figure based on a plot from <a href=\"https://mistral.ai/news/mixtral-8x22b\">https://mistral.ai/news/mixtral-8x22b</a>)</em></figcaption></figure></div><p></p><h2><strong>1.2 Llama 3: Larger data is better!</strong></h2><p><a href=\"https://arxiv.org/abs/2302.13971\">Meta AI's first Llama model release</a> in February 2023 was a big breakthrough for openly available LLM and was a pivotal moment for open(-source) LLMs. So, naturally, everyone was excited about the <a href=\"https://arxiv.org/abs/2307.09288\">Llama 2 release</a> last year. Now, the Llama 3 models, which <a href=\"https://ai.meta.com/blog/meta-llama-3/\">Meta AI has started to roll out</a>, are similarly exciting.</p><p>While Meta is still training some of their largest models (e.g., the 400B variant), they released models in the familiar 8B and 70B size ranges. And they are good! Below, I added the MMLU scores from the official <a href=\"https://ai.meta.com/blog/meta-llama-3/\">Llama 3 blog article</a> to the Mixtral plot I shared earlier.<br/></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!7FGP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!7FGP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 424w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 848w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 1272w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":804,\"width\":1376,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"804\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!7FGP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!7FGP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 424w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 848w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 1272w, https://substackcdn.com/image/fetch/$s_!7FGP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ddd66f7-c921-4372-b1d6-d32b6bb5e4c4_1376x804.png 1456w\" width=\"1376\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>A comparison between Llama 3, Mixtral, and other LLMs. (Annotated figure based on a plot from <a href=\"https://mistral.ai/news/mixtral-8x22b\">https://mistral.ai/news/mixtral-8x22b</a>)</em></figcaption></figure></div><p>Overall, the Llama 3 architecture is almost identical to Llama 2. The main differences are the increased vocabulary size and the fact that Llama 3 also uses grouped-query attention for the smaller-sized model. If you are looking for a grouped-query attention explainer, I've written about it here: </p><div class=\"digest-post-embed\" data-attrs='{\"nodeId\":\"7b9846f6-fc5c-4d5b-9e34-75b9f3195ca8\",\"caption\":\"In this edition of the newsletter, we direct our attention to one of the most prominent highlights of the summer: the release of the Llama 2 base and chat models, as well as CodeLlama, the latest highlights in the open-source AI large language model (LLM) landscape.\",\"cta\":null,\"showBylines\":true,\"size\":\"sm\",\"isEditorNode\":true,\"title\":\"New Foundation Models: CodeLlama and other highlights in Open-Source AI\",\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"bio\":\"Sebastian is a machine learning and AI researcher with over a decade of experience in the field. He is very passionate about explaining complex technical concepts and \\\"taking the magic out of AI.\\\"\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"is_guest\":false,\"bestseller_tier\":null}],\"post_date\":\"2023-08-26T11:34:03.094Z\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/49fcbda7-05d2-4b16-87a1-5febd0df9406_2126x1382.png\",\"cover_image_alt\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/ahead-of-ai-11-new-foundation-models\",\"section_name\":null,\"video_upload_id\":null,\"id\":136352403,\"type\":\"newsletter\",\"reaction_count\":108,\"comment_count\":14,\"publication_id\":null,\"publication_name\":\"Ahead of AI\",\"publication_logo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4dcbe6f-2617-404f-8368-9bc428272016_1280x1280.png\",\"belowTheFold\":true}'></div><p>Below are the configuration files used for implementing Llama 2 and Llama 3 in LitGPT, which help show the main differences at a glance.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!mHzH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!mHzH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 424w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 848w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 1272w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/f77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":996,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"996\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!mHzH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!mHzH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 424w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 848w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 1272w, https://substackcdn.com/image/fetch/$s_!mHzH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77f7c9c-38fc-4068-9104-100356d2b266_1600x1095.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A comparison of Llama 2 and Llama 3 configurations via LitGPT, <a href=\"https://github.com/Lightning-AI/litgpt\">https://github.com/Lightning-AI/litgpt</a></figcaption></figure></div><p></p><p></p><p><strong>Training data size</strong></p><p>The main contributor to the substantially better performance compared to Llama 2 is the much larger dataset. Llama 3 was trained on 15 trillion tokens, as opposed to \"only\" 2 trillion for Llama 2.</p><p>This is a very interesting finding because, as the <a href=\"https://ai.meta.com/blog/meta-llama-3/\">Llama 3 blog post</a> notes, according to the Chinchilla scaling laws, the optimal amount of training data for an 8 billion parameter model is much smaller, approximately 200 billion tokens. Moreover, the authors of Llama 3 observed that both the 8 billion and 70 billion parameter models demonstrated log-linear improvements even at the 15 trillion scale. This suggests that we (that is, researchers in general) could further enhance the model with more training data beyond 15 trillion tokens.</p><p><strong>Instruction finetuning and alignment</strong></p><p>For instruction finetuning and alignment, researchers usually choose between using reinforcement learning with human feedback (RLHF) via proximal policy optimization (PPO) or the reward-model-free direct preference optimization (DPO). Interestingly, the Llama 3 researchers did not favor one over the other; they used both! (More on PPO and DPO in a later section.)</p><p>The <a href=\"https://ai.meta.com/blog/meta-llama-3/\">Llama 3 blog post</a> stated that a Llama 3 research paper would follow in the coming month, and I am looking forward to the additional details that will hopefully be shared in this article.</p><h2><strong>1.3 Phi-3: Higher-quality data is better!</strong></h2><p>Just one week after the big Llama 2 release, Microsoft shared their new Phi-3 LLM. According to the benchmarks in the <a href=\"https://arxiv.org/abs/2404.14219\">technical report</a>, even the smallest Phi-3 model outperforms the Llama 3 8B model despite being less than half its size.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!mFbN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!mFbN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 424w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 848w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 1272w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":834,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"834\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!mFbN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!mFbN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 424w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 848w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 1272w, https://substackcdn.com/image/fetch/$s_!mFbN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fc3e2df-8ca9-4594-b821-4b2afe200d5e_1600x917.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A comparison between Phi-3, Llama 3, Mixtral, and other LLMs. (Annotated figure based on a plot from <a href=\"https://mistral.ai/news/mixtral-8x22b\">https://mistral.ai/news/mixtral-8x22b</a>)</figcaption></figure></div><p>Notably, Phi-3, which is based on the Llama architecture, has been trained on 5x fewer tokens than Llama 3 (3.3 trillion instead of 15 trillion). Phi-3 even uses the same tokenizer with a vocabulary size of 32,064 as Llama 2, which is much smaller than the Llama 3 vocabulary size.</p><p>Also, Phi-3-mini has \"only\" 3.8 billion parameters, which is less than half the size of Llama 3 8B.</p><p>So, What is the secret sauce? According to the technical report, it's dataset quality over quantity: \"heavily filtered web data and synthetic data\".</p><p>The paper didn't go into too much detail regarding the data curation, but it largely follows the recipe used for previous Phi models. I wrote more about Phi models a few months ago here: </p><div class=\"digest-post-embed\" data-attrs='{\"nodeId\":\"b0d35360-d0d7-421b-8aeb-a54c1da011e1\",\"caption\":\"In Ahead of AI, I try to strike a balance between discussing recent research, explaining AI-related concepts, and delving into general AI-relevant news and developments. Given that the previous issues leaned heavily towards research, I aim to address the latest trends in this issue.\",\"cta\":null,\"showBylines\":true,\"size\":\"sm\",\"isEditorNode\":true,\"title\":\"LLM Business and Busyness: Recent Company Investments and AI Adoption, New Small Openly Available LLMs, and LoRA Research\",\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"bio\":\"Sebastian is a machine learning and AI researcher with over a decade of experience in the field. He is very passionate about explaining complex technical concepts and \\\"taking the magic out of AI.\\\"\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"is_guest\":false,\"bestseller_tier\":null}],\"post_date\":\"2023-10-08T10:55:14.911Z\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/08b6f6cf-1650-4e01-8675-f3aabba02861_1024x1024.jpeg\",\"cover_image_alt\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/ahead-of-ai-12-llm-businesses\",\"section_name\":null,\"video_upload_id\":null,\"id\":137751955,\"type\":\"newsletter\",\"reaction_count\":73,\"comment_count\":17,\"publication_id\":null,\"publication_name\":\"Ahead of AI\",\"publication_logo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4dcbe6f-2617-404f-8368-9bc428272016_1280x1280.png\",\"belowTheFold\":true}'></div><p>As of this writing, people are still unsure whether Phi-3 is really as good as promised. For instance, many people I talked to noted that Phi-3 is much worse than Llama 3 for non-benchmark tasks.</p><p></p><h2><strong>1.4 Conclusion</strong></h2><p>Based on the three major releases described above, this has been an exceptional month for openly available LLMs. And I haven't even talked about my favorite model, OpenELM, which is discussed in the next section.</p><p>Which model should we use in practice? I think all three models above are attractive for different reasons. Mixtral has a lower active-parameter count than Llama 3 70B but still maintains a pretty good performance level. Phi-3 3.8B may be very appealing for mobile devices; according to the authors, a quantized version of it can run on an iPhone 14. And Llama 3 8B might be the most interesting all-rounder for fine-tuning since it can be comfortably fine-tuned on a single GPU when using LoRA.<br/></p><div class=\"subscription-widget-wrap-editor\" data-attrs='{\"url\":\"https://magazine.sebastianraschka.com/subscribe?\",\"text\":\"Subscribe\",\"language\":\"en\"}' data-component-name=\"SubscribeWidgetToDOM\"><div class=\"subscription-widget show-subscribe\"><div class=\"preamble\"><p class=\"cta-caption\">Ahead of AI is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><form class=\"subscription-widget-subscribe\"><input class=\"email-input\" name=\"email\" placeholder=\"Type your email…\" tabindex=\"-1\" type=\"email\"/><input class=\"button primary\" type=\"submit\" value=\"Subscribe\"/><div class=\"fake-input-wrapper\"><div class=\"fake-input\"></div><div class=\"fake-button\"></div></div></form></div></div><p></p><h1>2. OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</h1><p></p><p><a href=\"https://arxiv.org/abs/2404.14619\">OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</a> is the latest LLM model suite and paper shared by researchers at Apple, aiming to provide small LLMs for deployment on mobile devices.</p><p>Similar to the <a href=\"https://magazine.sebastianraschka.com/p/research-papers-in-february-2024?utm_source=profile&amp;utm_medium=reader2\">OLMo</a>, it's refreshing to see an LLM paper that shares details discussing the architecture, training methods, and training data. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!m9lw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!m9lw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 424w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 848w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 1272w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":369,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"369\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!m9lw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!m9lw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 424w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 848w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 1272w, https://substackcdn.com/image/fetch/$s_!m9lw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ee20e50-64dc-477c-93bd-10e1986eb207_1498x380.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>Comparison between OpenELM and other open-source LLMs that share datasets, code, and weights (there are not many out there that are similarly open). Annotated table from OpenELM paper, <a href=\"https://arxiv.org/abs/2404.14619\">https://arxiv.org/abs/2404.14619</a>.</em></figcaption></figure></div><p></p><p>Let's start with the most interesting tidbits:</p><ul><li><p>OpenELM comes in 4 relatively small and convenient sizes: 270M, 450M, 1.1B, and 3B</p></li><li><p>For each size, there's also an instruct-version available trained with <a href=\"https://arxiv.org/abs/2309.06657\">rejection sampling</a> and <a href=\"https://magazine.sebastianraschka.com/i/142924793/rlhf-vs-direct-preference-optimization-dpo\">direct preference optimization</a></p></li><li><p>OpenELM performs slightly better than OLMo even though it's trained on 2x fewer tokens</p></li><li><p>The main architecture tweak is a layer-wise scaling strategy</p></li></ul><p></p><h3><strong>2.1 Architecture details</strong></h3><p>Besides the layer-wise scaling strategy (more details later), the overall architecture settings and hyperparameter configuration are relatively similar to other LLMs like OLMo and Llama, as summarized in the figure below.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!DGF6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!DGF6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 424w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 848w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 1272w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/deda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":1224,\"width\":1382,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"1224\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!DGF6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!DGF6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 424w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 848w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 1272w, https://substackcdn.com/image/fetch/$s_!DGF6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdeda0d03-b19e-4387-887e-ad6915d8980a_1382x1224.png 1456w\" width=\"1382\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Architecture and hyperparameter comparison between OpenELM, the smallest OLMo model, and the smallest Llama 2 model. <em>Annotated table from OpenELM paper, <a href=\"https://arxiv.org/abs/2404.14619\">https://arxiv.org/abs/2404.14619</a>.</em></figcaption></figure></div><p></p><h3><strong>2.2 Training dataset</strong></h3><p>Sharing details is different from explaining them as research papers aimed to do when I was a student. For instance, they sampled a relatively small subset of 1.8T tokens from various public datasets (<a href=\"https://arxiv.org/abs/2306.01116\">RefinedWeb</a>, <a href=\"https://github.com/togethercomputer/RedPajama-Data\">RedPajama</a>, <a href=\"https://arxiv.org/abs/2101.00027\">The PILE</a>, and <a href=\"https://arxiv.org/abs/2402.00159\">Dolma</a>). This subset was 2x smaller than Dolma, which was used for training OLMo. But what was the rationale for this subsampling, and what were the sampling criteria?</p><p>One of the authors kindly followed up with me on that saying \"Regarding dataset: We did not have any rationale behind dataset sampling, except we wanted to use public datasets of about 2T tokens (following LLama2).\"</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!sQPT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!sQPT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 424w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 848w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 1272w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/aab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":812,\"width\":1028,\"resizeWidth\":499,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"394.15175097276267\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!sQPT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!sQPT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 424w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 848w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 1272w, https://substackcdn.com/image/fetch/$s_!sQPT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faab156e5-6394-4e82-bb35-0266eea92b07_1028x812.png 1456w\" width=\"499\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>Number of tokens used for training OpenELM vs the original number of tokens in the dataset (note that the precise token number depends on the tokenizer used). Annotated table from OpenELM paper, <a href=\"https://arxiv.org/abs/2404.14619\">https://arxiv.org/abs/2404.14619</a>.</em></figcaption></figure></div><p></p><h3><strong>2.3 Layer-wise scaling</strong></h3><p>The layer-wise scaling strategy (adopted from the <a href=\"https://arxiv.org/abs/2008.00623\">DeLighT: Deep and Light-weight Transformer</a> paper) is very interesting. Essentially, the researchers gradually widen the layers from the early to the later transformer blocks. In particular, keeping the head size constant, the researchers increase the number of heads in the attention module. They also scale the hidden dimension of the feed-forward module, as illustrated in the figure below.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!W5GR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!W5GR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 424w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 848w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 1272w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":1160,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"1160\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!W5GR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!W5GR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 424w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 848w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 1272w, https://substackcdn.com/image/fetch/$s_!W5GR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32bfc963-9601-445d-a47b-bcd6dbd3e2af_1556x1240.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>LLM architecture based on my <a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">Build a Large Language Model from Scratch</a> book.</em></figcaption></figure></div><p>I wish there was an ablation study training an LLM with and without the layer-wise scaling strategy on the same dataset. But those experiments are expensive, and I can understand why it wasn't done.</p><p>However, we can find ablation studies in the <a href=\"https://arxiv.org/abs/2008.00623\">DeLighT: Deep and Light-weight Transformer</a> paper that first introduced the layer-wise scaling on a smaller dataset based on the original encoder-decoder architecture, as shown below.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!dKje!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!dKje!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 424w, https://substackcdn.com/image/fetch/$s_!dKje!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 848w, https://substackcdn.com/image/fetch/$s_!dKje!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 1272w, https://substackcdn.com/image/fetch/$s_!dKje!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":733,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"733\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!dKje!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!dKje!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 424w, https://substackcdn.com/image/fetch/$s_!dKje!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 848w, https://substackcdn.com/image/fetch/$s_!dKje!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 1272w, https://substackcdn.com/image/fetch/$s_!dKje!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F04bdcf64-ed1e-40fe-bc4e-066af26506df_1600x806.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">A comparison between standard transformer blocks and transformer-blocks with layer-wise (block-wise) scaling from the DeLighT paper, <a href=\"https://arxiv.org/abs/2008.00623\">https://arxiv.org/abs/2008.00623</a>.</figcaption></figure></div><p></p><h3><strong>2.4 LoRA vs DoRA</strong></h3><p>An interesting bonus I didn't expect was that the researchers compared LoRA and DoRA (<a href=\"https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch\">which I discussed a few weeks ago</a>) for parameter-efficient finetuning! It turns out that there wasn't a noticeable difference between the two methods, though.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!N8PT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!N8PT!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 424w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 848w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 1272w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":364,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"364\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!N8PT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!N8PT!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 424w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 848w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 1272w, https://substackcdn.com/image/fetch/$s_!N8PT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8dbb23d0-1c83-4127-b0cf-e954995225de_1600x400.png 1456w\" width=\"1456\"/></picture><div></div></div></a><figcaption class=\"image-caption\"><em>Modeling performance comparison between two parameter-efficient finetuning methods: LoRA and DoRA. Annotated table from OpenELM paper, <a href=\"https://arxiv.org/abs/2404.14619\">https://arxiv.org/abs/2404.14619</a>.</em></figcaption></figure></div><p></p><h3><strong>2.5 Conclusion</strong></h3><p>While the paper doesn't answer any research questions, it's a great, transparent write-up of the LLM implementation details. The layer-wise scaling strategy might be something that we could see more often in LLMs from now on. Also, the paper is only one part of the release. For further details, Apple also shared the <a href=\"https://github.com/apple/corenet/tree/main/mlx_examples/open_elm\">OpenELM code on GitHub</a>.</p><p>Anyways, great work, and big kudos to the researchers (and Apple) for sharing!<br/></p><h1>3. Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</h1><p><em><a href=\"https://arxiv.org/abs/2404.10719\">Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</a></em> finally answers one of the key questions I've been raising in previous months. </p><p>Let's start with a brief overview before diving into the results: Both PPO (proximal policy optimization) and DPO (direct preference optimization) are popular methods for aligning LLMs via reinforcement learning with human feedback (RLHF). </p><p>RLHF is a key component of LLM development, and it's used to align LLMs with human preferences, for example, to improve the safety and helpfulness of LLM-generated responses. </p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!yZgE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!yZgE!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 424w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 848w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 1272w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":144,\"width\":1024,\"resizeWidth\":509,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"71.578125\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!yZgE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!yZgE!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 424w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 848w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 1272w, https://substackcdn.com/image/fetch/$s_!yZgE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F790c6b27-c9f1-4215-bd26-431735677b61_1024x144.png 1456w\" width=\"509\"/></picture><div></div></div></a><figcaption class=\"image-caption\"><em>The typical LLM training lifecycle</em></figcaption></figure></div><p>For a more detailed explanation and comparison, also see the <em>Evaluating Reward Modeling for Language Modeling section</em> in my <a href=\"https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms\">Tips for LLM Pretraining and Evaluating Reward Models</a> article that I shared last month.</p><h3><strong>3.1 What are RLHF-PPO and DPO?</strong></h3><p>RLHF-PPO, the original LLM alignment method, has been the backbone of OpenAI's <a href=\"https://arxiv.org/abs/2203.02155\">InstructGPT</a> and the LLMs deployed in ChatGPT. However, the landscape has shifted in recent months with the emergence of DPO-finetuned LLMs, which have made a significant impact on public leaderboards. This surge in popularity can be attributed to DPO's reward-free alternative, which is notably easier to use: Unlike PPO, DPO doesn't require training a separate reward model but uses a classification-like objective to update the LLM directly.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!dIar!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!dIar!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 424w, https://substackcdn.com/image/fetch/$s_!dIar!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 848w, https://substackcdn.com/image/fetch/$s_!dIar!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!dIar!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/ba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":924,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"924\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!dIar!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg\" srcset=\"https://substackcdn.com/image/fetch/$s_!dIar!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 424w, https://substackcdn.com/image/fetch/$s_!dIar!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 848w, https://substackcdn.com/image/fetch/$s_!dIar!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!dIar!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fba8981dc-9883-42fc-a1c5-f2a1d04d4ad3_1456x924.jpeg 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>Excerpt from <a href=\"https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms\">Tips for LLM Pretraining and Evaluating Reward Models</a> </em></figcaption></figure></div><p>Today, most LLMs on top of public leaderboards have been trained with DPO rather than PPO. Unfortunately, though, there have not been any direct head-to-head comparisons where the same model was trained with either PPO or DPO using the same dataset until this new paper came along. </p><h3><strong>3.2 PPO is generally better than DPO</strong></h3><p><em><a href=\"https://arxiv.org/abs/2404.10719\">Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</a></em> is a well-written paper with lots of experiments and results, but the main takeaways are that PPO is generally better than DPO, and DPO suffers more heavily from out-of-distribution data.</p><p>Here, out-of-distribution data means that the LLM has been previously trained on instruction data (using supervised finetuning) that is different from the preference data for DPO. For example, an LLM has been trained on the general Alpaca dataset before being DPO-finetuned on a different dataset with preference labels. (One way to improve DPO on out-of-distribution data is to add a supervised instruction-finetuning round on the preference dataset before following up with DPO finetuning).</p><p>The main findings are summarized in the figure below.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!fS-X!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!fS-X!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 424w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 848w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 1272w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":823,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"823\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!fS-X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!fS-X!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 424w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 848w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 1272w, https://substackcdn.com/image/fetch/$s_!fS-X!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f060951-06bb-4d03-8c89-51b53241b97c_1600x904.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Annotated table from the <em>Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</em> (<a href=\"https://arxiv.org/abs/2404.10719\">https://arxiv.org/abs/2404.10719</a>) paper.</figcaption></figure></div><p>In addition to the main results above, the paper includes several additional experiments and ablation studies that I recommend checking out if you are interested in this topic. </p><h3><strong>3.3 Best practices</strong></h3><p>Furthermore, interesting takeaways from this paper include best-practice recommendations when using DPO and PPO.</p><p>For instance, if you use DPO, make sure to perform supervised finetuning on the preference data first. Also, iterative DPO, which involves labeling additional data with an existing reward model, is better than DPO on the existing preference data.</p><p>If you use PPO, the key success factors are large batch sizes, advantage normalization, and parameter updates via an exponential moving average.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!XQIG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!XQIG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 424w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 848w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 1272w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":1005,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"1005\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!XQIG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!XQIG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 424w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 848w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 1272w, https://substackcdn.com/image/fetch/$s_!XQIG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5653e39f-cb9e-4987-bbac-4e420864ed18_1600x1104.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><em>An excerpt of a preference dataset (examples taken from the <a href=\"https://huggingface.co/datasets/Intel/orca_dpo_pairs\">Orca dataset</a>)</em></figcaption></figure></div><h3><strong>3.4 Conclusion</strong></h3><p>Based on this paper's results, PPO seems superior to DPO if used correctly. However, given that DPO is more straightforward to use and implement, I expect DPO to remain a popular go-to method. </p><p>A good practical recommendation may be to use PPO if you have ground truth reward labels (so you don't have to pretrain your own reward model) or if you can download an in-domain reward model. Otherwise, use DPO for simplicity.</p><p>Also, based on what we know from the LLama 3 blog post, we don't have to decide whether to use PPO or DPO, but we can use both! For instance, the recipe behind Llama 3 has been the following pipeline: Pretraining → supervised finetuning → rejection sampling → PPO → DPO. (I am hoping the Llama 3 developers will share a paper with more details soon!)</p><p><br/></p><div><hr/></div><h3>Understanding LLMs (really well)</h3><p>One of the best ways to understand LLMs is to code one from scratch!</p><p>If you are interested in learning more about LLMs, I am covering, implementing, and explaining the whole LLM lifecycle in my <a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">\"Build a Large Language Model from Scratch\" book</a>, which is currently available at a discounted price before it is published in Summer 2024.</p><p>Chapter 5, which covers the pretraining, was just released 2 weeks ago. If this sounds interesting and useful to you, you can take a sneak peak at the code on GitHub <a href=\"https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\">here</a>.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!dHID!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!dHID!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 424w, https://substackcdn.com/image/fetch/$s_!dHID!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 848w, https://substackcdn.com/image/fetch/$s_!dHID!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 1272w, https://substackcdn.com/image/fetch/$s_!dHID!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/db008672-3d08-4768-887a-6a591c76e6f9_1600x879.png\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":800,\"width\":1456,\"resizeWidth\":null,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"800\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!dHID!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png\" srcset=\"https://substackcdn.com/image/fetch/$s_!dHID!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 424w, https://substackcdn.com/image/fetch/$s_!dHID!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 848w, https://substackcdn.com/image/fetch/$s_!dHID!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 1272w, https://substackcdn.com/image/fetch/$s_!dHID!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb008672-3d08-4768-887a-6a591c76e6f9_1600x879.png 1456w\" width=\"1456\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">“Build a Large Language Model from Scratch” book</a></figcaption></figure></div><div><hr/></div><p></p><p><br/><br/></p><h1>4. Other Interesting Research Papers In April</h1><p>Below is a selection of other interesting papers I stumbled upon this month. Even compared to strong previous months, I think that LLM research in April has been really exceptional.</p><p></p><p><strong>KAN: Kolmogorov–Arnold Networks</strong> by Liu, Wang, Vaidya, <em>et al.</em> (30 Apr), <a href=\"https://arxiv.org/abs/2404.19756\">https://arxiv.org/abs/2404.19756</a></p><ul><li><p>Kolmogorov-Arnold Networks (KANs), which replace linear weight parameters with learnable spline-based functions on edges and lack fixed activation functions, seem to offer an attractive new alternative to Multi-Layer Perceptrons, which they outperform in accuracy, neural scaling, and interpretability.</p></li></ul><p><strong>When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively</strong> by Labruna, Ander Campos, and Azkune (30 Apr), <a href=\"https://arxiv.org/abs/2404.19705\">https://arxiv.org/abs/2404.19705</a></p><ul><li><p>This paper proposes a custom training approach for LLMs that teaches them to either utilize their parametric memory or an external information retrieval  system via a special token &lt;RET&gt; when it doesn't know the answer.</p></li></ul><p><strong>A Primer on the Inner Workings of Transformer-based Language Models</strong> by Ferrando, Sarti, Bisazza, and Costa-jussa (30 Apr), <a href=\"https://arxiv.org/abs/2405.00208\">https://arxiv.org/abs/2405.00208</a></p><ul><li><p>This primer offers a succinct technical overview of the techniques used to interpret Transformer-based, decoder-only language models</p></li></ul><p><strong>RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing</strong> by Hu and Lu (30 Apr), <a href=\"https://arxiv.org/abs/2404.19543\">https://arxiv.org/abs/2404.19543</a></p><ul><li><p>This survey provides a comprehensive view of retrieval-augmented LLMs, detailing their components, structures, applications, and evaluation methods</p></li></ul><p><strong>Better &amp; Faster Large Language Models via Multi-token Prediction</strong> by Gloeckle, Idrissi, Rozière, <em>et al.</em> (30 Apr), <a href=\"https://arxiv.org/abs/2404.19737\">https://arxiv.org/abs/2404.19737</a></p><ul><li><p>This paper suggests that training LLMs to predict multiple future tokens simultaneously rather than just the next token not only improves sample efficiency but also improves performance on generative tasks.</p></li></ul><p><strong>LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report</strong> by Zhao, Wang, Abid, <em>et al.</em> (28 Apr), <a href=\"https://arxiv.org/abs/2405.00732\">https://arxiv.org/abs/2405.00732</a></p><ul><li><p>LoRA is one of the most wide parameter-efficient finetuning techniques, and this study finds that 4-bit LoRA finetuned models significantly outperform both their base models and GPT-4.</p></li></ul><p><strong>Make Your LLM Fully Utilize the Context</strong>, An, Ma, Lin <em>et al.</em> (25 Apr), <a href=\"https://arxiv.org/abs/2404.16811\">https://arxiv.org/abs/2404.16811</a></p><ul><li><p>The study introduces FILM-7B, a model trained using an information-intensive approach to address the \"lost-in-the-middle\" challenge, which describes the problem where LLMs are not able to retrieve information if it's not at the beginning or end of the context window.</p></li></ul><p><strong>Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding</strong> by Elhoushi, Shrivastava, Liskovich, <em>et al.</em> (25 Apr), <a href=\"https://arxiv.org/abs/2404.16710\">https://arxiv.org/abs/2404.16710</a></p><ul><li><p>LayerSkip can accelerate the inference of LLMs by using layer dropout and early exit loss during training, and implementing self-speculative decoding during inference.</p></li></ul><p><strong>Retrieval Head Mechanistically Explains Long-Context Factuality</strong> by Wu, Wang, Xiao, <em>et al.</em> (24 Apr), <a href=\"https://arxiv.org/abs/2404.15574\">https://arxiv.org/abs/2404.15574</a></p><ul><li><p>This paper explores how transformer-based models with long-context capabilities use specific \"retrieval heads\" in their attention mechanisms to effectively retrieve information, revealing that these heads are universal, sparse, intrinsic, dynamically activated, and crucial for tasks requiring reference to prior context or reasoning.</p></li></ul><p></p><p><strong>Graph Machine Learning in the Era of Large Language Models (LLMs)</strong> by Fan, Wang, Huang, <em>et al.</em> (23 Apr), <a href=\"https://arxiv.org/abs/2404.14928\">https://arxiv.org/abs/2404.14928</a></p><ul><li><p>This survey paper describes, among others, how Graph Neural Networks and LLMs are increasingly integrated to improve graph machine learning and reasoning capabilities.<br/></p></li></ul><p><strong>NExT: Teaching Large Language Models to Reason about Code Execution</strong> by Ni, Allamanis, Cohan, <em>et al.</em> (23 Apr), <a href=\"https://arxiv.org/abs/2404.14662\">https://arxiv.org/abs/2404.14662</a></p><ul><li><p>NExT is a method to improve how LLMs understand and fix code by teaching them to analyze program execution.</p></li></ul><p></p><p><strong>Multi-Head Mixture-of-Experts</strong> by Wu, Huang, Wang, and Wei (23 Apr), <a href=\"https://arxiv.org/abs/2404.15045\">https://arxiv.org/abs/2404.15045</a></p><ul><li><p>The proposed Multi-Head Mixture-of-Experts (MH-MoE) model addresses Sparse Mixtures of Experts' issues of low expert activation and poor handling of multiple semantic concepts by introducing a multi-head mechanism that splits tokens into sub-tokens processed by diverse experts in parallel.</p></li></ul><p><strong>A Survey on Self-Evolution of Large Language Models</strong> by Tao, Lin, Chen, <em>et al.</em> (22 Apr), <a href=\"https://arxiv.org/abs/2404.14662\">https://arxiv.org/abs/2404.14662</a></p><ul><li><p>This work presents a comprehensive survey of self-evolution approaches in LLMs, proposing a conceptual framework for LLM self-evolution and identifying challenges and future directions to enhance these models' capabilities.</p></li></ul><p><strong>OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</strong> by Mehta, Sekhavat, Cao <em>et al.</em> (22 Apr), <a href=\"https://arxiv.org/abs/2404.14619\">https://arxiv.org/abs/2404.14619</a></p><ul><li><p>OpenELM by researchers from Apple is a LLM suite by Apple in the spirit of OLMo (a model family I covered previously), including full training and evaluation frameworks, logs, checkpoints, configurations, and other artifacts for reproducible research.</p></li></ul><p></p><p><strong>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</strong> by Abdin, Jacobs, Awan, <em>et al.</em> (Apr 22), <a href=\"https://arxiv.org/abs/2404.14219\">https://arxiv.org/abs/2404.14219</a></p><ul><li><p>Phi-3-mini is a 3.8 billion parameter LLM trained on 3.3 trillion tokens that matches the performance of larger models like Mixtral 8x7B and GPT-3.5 according to benchmarks.</p></li></ul><p></p><p><strong>How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study</strong> by Huang, Ma, and Qin (22 Apr), <a href=\"https://arxiv.org/abs/2404.14047\">https://arxiv.org/abs/2404.14047</a></p><ul><li><p>This empirical study finds that Meta's LLaMA3 model reveals significant performance degradation at ultra-low bit-widths.</p></li></ul><p></p><p><strong>The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions</strong> by Wallace, Xiao, Leike, <em>et al.</em> (19 Apr), <a href=\"https://arxiv.org/abs/2404.13208\">https://arxiv.org/abs/2404.13208</a></p><ul><li><p>This study introduces an instruction hierarchy for LLMs to prioritize trusted prompts, enhancing their robustness against attacks without compromising their standard capabilities.</p></li></ul><p></p><p><strong>OpenBezoar: Small, Cost-Effective and Open Models Trained on Mixes of Instruction Data</strong> by Dissanayake, Lowe, Gunasekara, and Ratnayake (18 Apr), <a href=\"https://arxiv.org/abs/2404.12195\">https://arxiv.org/abs/2404.12195</a></p><ul><li><p>The research finetunes the OpenLLaMA 3Bv2 model using synthetic data from Falcon-40B and techniques like RLHF and DPO, achieving top performance in LLM tasks at a reduced model size by systematically filtering and finetuning data.</p></li></ul><p></p><p><strong>Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing</strong> by Tian, Peng, Song,<em> et al.</em> (18 Apr), <a href=\"https://arxiv.org/abs/2404.12253\">https://arxiv.org/abs/2404.12253</a></p><ul><li><p>Despite the impressive capabilities of LLMs in various tasks, they struggle with complex reasoning and planning; the proposed AlphaLLM integrates Monte Carlo Tree Search to create a self-improving loop, enhancing LLMs' performance in reasoning tasks without additional data annotations.</p></li></ul><p></p><p><strong>When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes</strong> by Yehudai and Bendel (18 Apr), <a href=\"https://arxiv.org/abs/2404.12365\">https://arxiv.org/abs/2404.12365</a></p><ul><li><p>FastFit is a new Python package that rapidly and accurately handles few-shot classification for language tasks with many similar classes by integrating batch contrastive learning and token-level similarity scoring, showing a 3-20x increase in training speed and superior performance over other methods like SetFit and HF Transformers.</p></li></ul><p></p><p><strong>A Survey on Retrieval-Augmented Text Generation for Large Language Models</strong> by Huang and Huang (17 Apr), <a href=\"https://arxiv.org/abs/2404.10981\">https://arxiv.org/abs/2404.10981</a></p><ul><li><p>This survey article discusses how Retrieval-Augmented Generation (RAG) combines retrieval techniques and deep learning to improve LLMs by dynamically incorporating up-to-date information, categorizes the RAG process, reviews recent developments, and proposes future research directions</p></li></ul><p><br/></p><p><strong>How Faithful Are RAG Models? Quantifying the Tug-of-War Between RAG and LLMs' Internal Prior</strong> by Wu, Wu, and Zou (16 Apr), <a href=\"https://arxiv.org/abs/2404.10198\">https://arxiv.org/abs/2404.10198</a></p><ul><li><p>Providing correct retrieved information generally corrects errors in large language models like GPT-4, but incorrect information is often repeated unless countered by strong internal knowledge.</p></li></ul><p></p><p><strong>Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies </strong>by Li, Xie, and Cubuk (16 Apr), <a href=\"https://arxiv.org/abs/2404.08197\">https://arxiv.org/abs/2404.08197</a></p><ul><li><p>This paper explores the scaling down of Contrastive Language-Image Pretraining (CLIP) to fit limited computational budgets, demonstrating that high-quality, smaller datasets often outperform larger, lower-quality ones, and that smaller ViT models are optimal for these datasets. </p></li></ul><p></p><p><strong>Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</strong> by Xu, Fu, Gao <em>et al.</em> (16 Apr), <a href=\"https://arxiv.org/abs/2404.10719\">https://arxiv.org/abs/2404.10719</a></p><ul><li><p>This research explores the effectiveness of Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO) in Reinforcement Learning from Human Feedback (RLHF), finding that PPO can to surpass all other alternative methods in all cases if applied properly.</p></li></ul><p></p><p><strong>Learn Your Reference Model for Real Good Alignment</strong> by Gorbatovski, Shaposhnikov, Malakhov, <em>et al.</em> (15 Apr), <a href=\"https://arxiv.org/abs/2404.09656\">https://arxiv.org/abs/2404.09656</a></p><ul><li><p>The research highlights that the new alignment method, Trust Region Direct Preference Optimization (TR-DPO), which updates the reference policy during training, outperforms existing techniques by improving model quality across multiple parameters, demonstrating up to a 19% improvement on specific datasets.</p></li></ul><p></p><p><strong>Chinchilla Scaling: A Replication Attempt</strong> by Besiroglu, Erdil, Barnett, and You (15 Apr), <a href=\"https://arxiv.org/abs/2404.10102\">https://arxiv.org/abs/2404.10102</a></p><ul><li><p>The authors attempt to replicate one of Hoffmann et al.'s methods for estimating compute-optimal scaling laws, finding inconsistencies and implausible results compared to the original estimates from other methods.</p></li></ul><p></p><p><strong>State Space Model for New-Generation Network Alternative to Transformers: A Survey</strong> by Wang, Wang, Ding, <em>et al.</em> (15 Apr), <a href=\"https://arxiv.org/abs/2404.09516\">https://arxiv.org/abs/2404.09516</a></p><ul><li><p>The paper provides a comprehensive review and experimental analysis of State Space Models (SSM) as an efficient alternative to the Transformer architecture, detailing the principles of SSM, its applications across diverse domains, and offering statistical comparisons to demonstrate its advantages and potential areas for future research.</p></li></ul><p></p><p><strong>LLM In-Context Recall is Prompt Dependent</strong> by Machlab and Battle (13 Apr), <a href=\"https://arxiv.org/abs/2404.08865\">https://arxiv.org/abs/2404.08865</a></p><ul><li><p>The research assesses the in-context recall ability of various LLMs by embedding a factoid within a block of text and evaluating the models' performance in retrieving this information under different conditions, revealing that performance is influenced by both the prompt content and potential biases in training data.</p></li></ul><p></p><p><strong>Dataset Reset Policy Optimization for RLHF</strong> by Chang, Zhan, Oertell, et al. (12 Apr), <a href=\"https://arxiv.org/abs/2404.08495\">https://arxiv.org/abs/2404.08495</a></p><ul><li><p>This work introduces Dataset Reset Policy Optimization (DR-PO), a new Reinforcement Learning from Human Preference-based feedback (RLHF) algorithm that enhances training by integrating an offline preference dataset directly into the online policy training.<br/></p></li></ul><p><strong>Pre-training Small Base LMs with Fewer Tokens</strong> by Sanyal, Sanghavi, and Dimakis (12 Apr), <a href=\"https://arxiv.org/abs/2404.08634\">https://arxiv.org/abs/2404.08634</a></p><ul><li><p>The study introduces \"Inheritune,\" a method for developing smaller base language models by inheriting a few transformer blocks from larger models and training on a tiny fraction of the larger model's data, demonstrating that these smaller models perform comparably to larger models despite using significantly less training data and resources.</p></li></ul><p></p><p><strong>Rho-1: Not All Tokens Are What You Need</strong> by Lin, Gou, Gong <em>et al.</em>, (11 Apr), <a href=\"https://arxiv.org/abs/2404.07965\">https://arxiv.org/abs/2404.07965</a></p><ul><li><p>Rho-1 is a new language model that is trained selectively on tokens that demonstrate higher excess loss as opposed to traditional next-token prediction methods. </p></li></ul><p></p><p><strong>Best Practices and Lessons Learned on Synthetic Data for Language Models</strong> by Liu, Wei, Liu, <em>et al.</em> (11 Apr), <a href=\"https://arxiv.org/abs/2404.07503\">https://arxiv.org/abs/2404.07503</a></p><ul><li><p>This paper reviews synthetic data research in the context of LLMs.</p></li></ul><p></p><p><strong>JetMoE: Reaching Llama2 Performance with 0.1M Dollars</strong>, Shen, Guo, Cai, and Qin (11 Apr), <a href=\"https://arxiv.org/abs/2404.07413\">https://arxiv.org/abs/2404.07413</a></p><ul><li><p>JetMoE-8B, an 8-billion parameter, sparsely-gated Mixture-of-Experts model trained on 1.25 trillion tokens for under $100,000, outperforms more expensive models such as Llama2-7B by using only 2 billion parameters per input token and \"only\" 30,000 GPU hours.</p></li></ul><p></p><p><strong>LLoCO: Learning Long Contexts Offline</strong> by Tan, Li, Patil <em>et al.</em> (11 Apr), <a href=\"https://arxiv.org/abs/2404.07979\">https://arxiv.org/abs/2404.07979</a></p><ul><li><p>LLoCO is a method combining context compression, retrieval, and parameter-efficient finetuning with LoRA to effectively expand the context window of a LLaMA2-7B model to handle up to 128k tokens</p></li></ul><p></p><p><strong>Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</strong> by Munkhdalai, Faruqui, and Gopal (10 Apr), <a href=\"https://arxiv.org/abs/2404.07143\">https://arxiv.org/abs/2404.07143</a></p><ul><li><p>This research introduces a method to scale transformer-based LLMs for processing infinitely long inputs efficiently by combining several attention strategies within a single transformer block for tasks with extensive contextual demands.</p></li></ul><p></p><p><strong>Adapting LLaMA Decoder to Vision Transformer</strong> by Wang, Shao, Chen, <em>et al.</em> (10 Apr), <a href=\"https://arxiv.org/abs/2404.06773\">https://arxiv.org/abs/2404.06773</a></p><ul><li><p>This research adapts decoder-only transformer-based LLMs like Llama for computer vision by modifying a standard vision transformer (ViT) with techniques like a post-sequence class token and a soft mask strategy.</p></li></ul><p></p><p><strong>LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders</strong> by BehnamGhader, Adlakha, Mosbach, <em>et al.</em> (9 Apr), <a href=\"https://arxiv.org/abs/2404.05961\">https://arxiv.org/abs/2404.05961</a></p><ul><li><p>This research introduces a simple, unsupervised approach to transform decoder-style LLMs (like GPT and Llama) into strong text encoders via 1) disabling the causal attention mask, 2) masked next token prediction, and 3) unsupervised contrastive learning.</p></li></ul><p></p><p><strong>Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models</strong> by Bordt, Nori, Rodrigues, <em>et al</em>. (9 Apr), <a href=\"https://arxiv.org/abs/2404.06209\">https://arxiv.org/abs/2404.06209</a></p><ul><li><p>This study highlights critical issues of data contamination and memorization in LLMs, showing that LLMs often memorize popular tabular datasets and perform better on datasets seen during training, which leads to overfitting</p></li></ul><p></p><p><strong>MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</strong> by Hu, Tu, Han, <em>et al. </em>(9 Apr), <a href=\"https://arxiv.org/abs/2404.06395\">https://arxiv.org/abs/2404.06395</a></p><ul><li><p>This research introduces new resource-efficient \"small\" language models in the 1.2-2.4 billion parameter range, along with techniques such as the warmup-stable-decay learning rate scheduler, which is helpful for continuous pretraining and domain adaptation.</p></li></ul><p></p><p><strong>CodecLM: Aligning Language Models with Tailored Synthetic Data</strong> by Wang, Li, Perot, <em>et al</em>. (8 Apr), <a href=\"https://arxiv.org/abs/2404.05875\">https://arxiv.org/abs/2404.05875</a></p><ul><li><p>CodecLM introduces a framework using encode-decode principles and LLMs as codecs to adaptively generate high-quality synthetic data for aligning LLMs with various instruction distributions to improve their ability to follow complex, diverse instructions.</p></li></ul><p></p><p><strong>Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence</strong> by Peng, Goldstein, Anthony, <em>et al.</em> (8 Apr), <a href=\"https://arxiv.org/abs/2404.05892\">https://arxiv.org/abs/2404.05892</a></p><ul><li><p>Eagle and Finch are new sequence models based on the RWKV architecture, introducing features like multi-headed matrix states and dynamic recurrence.</p></li></ul><p></p><p><strong>AutoCodeRover: Autonomous Program Improvement</strong> by Zhang, Ruan, Fan, and Roychoudhury (8 Apr), <a href=\"https://arxiv.org/abs/2404.05427\">https://arxiv.org/abs/2404.05427</a></p><ul><li><p>AutoCodeRover is an automated approach utilizing LLMs and advanced code search to solve GitHub issues by modifying software programs.</p></li></ul><p></p><p><strong>Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation</strong> by Wan, Wang, Yong, <em>et al.</em> (5 Apr), <a href=\"https://arxiv.org/abs/2404.04256\">https://arxiv.org/abs/2404.04256</a></p><ul><li><p>Sigma is an approach to multi-modal semantic segmentation using a Siamese Mamba (structure state space model) network, which combines different modalities like thermal and depth with RGB and presents an alternative to CNN- and vision transformer-based approaches.</p></li></ul><p></p><p><strong>Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data</strong> by Zhang, Marone,  Li, <em>et al.</em> (5 Apr 2024), <a href=\"https://arxiv.org/abs/2404.03862\">https://arxiv.org/abs/2404.03862</a></p><ul><li><p>Quote-Tuning improves the trustworthiness and accuracy of large language models by training them to increase verbatim quoting from reliable sources by 55% to 130% compared to standard models.</p></li></ul><p></p><p><strong>ReFT: Representation Finetuning for Language Models</strong> by Wu, Arora, Wang, et al. (5 Apr), <a href=\"https://arxiv.org/abs/2404.03592\">https://arxiv.org/abs/2404.03592</a></p><ul><li><p>This paper introduces Representation Finetuning (ReFT) methods, analogous to parameter-efficient finetuning (PEFT), for adapting large models efficiently by modifying only their hidden representations rather than the full set of parameters.</p></li></ul><p></p><p><strong>CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues</strong> by Sreedhar, Rebedea, Ghosh, and Parisien (4 Apr), <a href=\"https://arxiv.org/abs/2404.03820\">https://arxiv.org/abs/2404.03820</a></p><ul><li><p>This paper introduces the CantTalkAboutThis dataset, which is designed to help LLMs stay on topic during task-oriented conversations (it includes synthetic dialogues across various domains, featuring distractor turns to challenge and train models to resist topic diversion).</p></li></ul><p></p><p><strong>Training LLMs over Neurally Compressed Text</strong> by Lester, Lee, Alemi, <em>et al.</em> (4 Apr), <a href=\"https://arxiv.org/abs/2404.03626\">https://arxiv.org/abs/2404.03626</a></p><ul><li><p>This paper introduces a method for training LLMs on neurally compressed text (text compressed by a small language model) using Equal-Info Windows, a technique that segments text into blocks of equal bit length, </p></li></ul><p></p><p><strong>Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences</strong> by Andriushchenko, Croce, and Flammarion (4 Apr), <a href=\"https://arxiv.org/abs/2404.02151\">https://arxiv.org/abs/2404.02151</a></p><ul><li><p>This paper introduces Direct Nash Optimization (DNO), a post-training method for LLMs that uses preference feedback from an oracle to iteratively improve model performance as alternative to other reinforcement learning with human feedback (RLHF) approaches.</p></li></ul><p></p><p><strong>Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models</strong> by Zhang, Liu, Xie, <em>et al.</em> (3 Apr), <a href=\"https://arxiv.org/abs/2404.02747\">https://arxiv.org/abs/2404.02747</a></p><ul><li><p>The study looks into how cross-attention functions in text-conditional diffusion models during inference, discovers that it stabilizes at a certain point, and finds that bypassing text inputs after this convergence point simplifies the process without compromising on output quality.</p></li></ul><p></p><p><strong>BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models</strong> by Luo, Hengzu, and Li (3 Apr), <a href=\"https://arxiv.org/abs/2404.02827\">https://arxiv.org/abs/2404.02827</a></p><ul><li><p>BAdam is a memory-efficient optimizer that improves the efficiency of finetuning LLMs, which is also easy to use and comes with only one additional hyperparameter.</p></li></ul><p></p><p><strong>On the Scalability of Diffusion-based Text-to-Image Generation</strong> by Li, Zou, Wang, <em>et al.</em> (3 Apr), <a href=\"https://arxiv.org/abs/2404.02883\">https://arxiv.org/abs/2404.02883</a></p><ul><li><p>This study empirically investigates the scaling properties of diffusion-based text-to-image models by analyzing the effects of scaling denoising backbones and training sets, uncovering that the efficiency of cross-attention and transformer blocks significantly influences performance, and identifying strategies for enhancing text-image alignment and learning efficiency at lower costs.</p></li></ul><p></p><p><strong>Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks</strong> by Andriushchenko, Croce, and Flammarion (2 Apr), <a href=\"https://arxiv.org/abs/2404.02151\">https://arxiv.org/abs/2404.02151</a></p><ul><li><p>This study reveals that even the latest safety-focused LLMs can be easily jailbroken using adaptive techniques, achieving nearly 100% success across various models through methods like adversarial prompting, exploiting API vulnerabilities, and token search space restriction.</p></li></ul><p></p><p><strong>Emergent Abilities in Reduced-Scale Generative Language Models</strong> by Muckatira, Deshpande, Lialin, and Rumshisky (2 Apr), <a href=\"https://arxiv.org/abs/2404.02204\">https://arxiv.org/abs/2404.02204</a></p><ul><li><p>This study finds that very \"small\" LLMs (from 1 to 165 million parameters) can also exhibit emergent properties if the dataset for pretraining is scaled down and simplified.</p></li></ul><p></p><p><strong>Long-context LLMs Struggle with Long In-context Learning</strong> by Li, Zheng, Do, <em>et al. </em>(2 Apr), <a href=\"https://arxiv.org/abs/2404.02060\">https://arxiv.org/abs/2404.02060</a></p><ul><li><p>LIConBench, a new benchmark focusing on long in-context learning and extreme-label classification, reveals that while LLMs excel up to 20K tokens, their performance drops in longer sequences, with GPT-4 being an exception, highlighting a gap in processing extensive context-rich information.</p></li></ul><p></p><p><strong>Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models</strong> by Raposo, Ritter, Richard <em>et al.</em> (2 Apr), <a href=\"https://arxiv.org/abs/2404.02258\">https://arxiv.org/abs/2404.02258</a></p><ul><li><p>This research introduces a method for transformer-based language models to dynamically allocate computational resources (FLOPs) across different parts of an input sequence, optimizing performance and efficiency by selecting specific tokens for processing at each layer.</p></li></ul><p></p><p><strong>Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models</strong> by Fei, Fan, Yu, et al. (6 Apr), <a href=\"https://arxiv.org/abs/2404.04478\">https://arxiv.org/abs/2404.04478</a></p><ul><li><p>This paper introduces Diffusion-RWKV, an adaptation of the RWKV architecture from NLP for diffusion models in image generation.</p></li></ul><p></p><p><strong>The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis</strong> by Yang, Li, Niu, <em>et al.</em> (1 Apr), <a href=\"https://arxiv.org/abs/2404.01204\">https://arxiv.org/abs/2404.01204</a></p><ul><li><p>This research identifies early-stage  capable of predicting the eventual LLMs, which is helpful analyzing LLMs during pretraining and improving the pretraining setup.</p></li></ul><p></p><p><strong>Bigger is not Always Better: Scaling Properties of Latent Diffusion Models</strong> by Mei, Tu, Delbracio, <em>et al.</em> (1 Apr), <a href=\"https://arxiv.org/abs/2404.01367\">https://arxiv.org/abs/2404.01367</a></p><ul><li><p>This study explores how the size of latent diffusion models affects sampling efficiency across different steps and tasks, revealing that smaller models often produce higher quality results within a given inference budget.</p></li></ul><p></p><p><strong>Do Language Models Plan Ahead for Future Tokens?</strong> by Wu, Morris, and Levine (1 Apr), <a href=\"https://arxiv.org/abs/2404.00859\">https://arxiv.org/abs/2404.00859</a></p><ul><li><p>The research paper finds empirical evidence that transformers anticipate future information during inference through \"pre-caching\" and \"breadcrumbs\" mechanisms.</p></li></ul><p></p><div><hr/></div><p></p><p></p><h1>Machine Learning Q and AI</h1><p></p><p>If you are looking for a book that explains intermediate to advanced topics in machine learning and AI in a focused manner, you might like my book, \"<a href=\"https://www.amazon.com/Machine-Learning-AI-Essential-Questions/dp/1718503768\">Machine Learning Q and AI</a>.\" The print version was just released two weeks ago!</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" data-component-name=\"Image2ToDOM\" href=\"https://substackcdn.com/image/fetch/$s_!ziY3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg\" target=\"_blank\"><div class=\"image2-inset\"><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/$s_!ziY3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 1456w\" type=\"image/webp\"/><img alt=\"\" class=\"sizing-normal\" data-attrs='{\"src\":\"https://substack-post-media.s3.amazonaws.com/public/images/0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg\",\"srcNoWatermark\":null,\"fullscreen\":null,\"imageSize\":null,\"height\":1028,\"width\":1384,\"resizeWidth\":727,\"bytes\":null,\"alt\":null,\"title\":null,\"type\":null,\"href\":null,\"belowTheFold\":true,\"topImage\":false,\"internalRedirect\":null,\"isProcessing\":false,\"align\":null,\"offset\":false}' height=\"539.9971098265896\" loading=\"lazy\" sizes=\"100vw\" src=\"https://substackcdn.com/image/fetch/$s_!ziY3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg\" srcset=\"https://substackcdn.com/image/fetch/$s_!ziY3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 424w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 848w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!ziY3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d39fd70-b494-4d68-9e76-ab3549f89cbe_1384x1028.jpeg 1456w\" width=\"727\"/></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button class=\"pencraft pc-reset pencraft icon-container restack-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-refresh-cw\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button class=\"pencraft pc-reset pencraft icon-container view-image\" tabindex=\"0\" type=\"button\"><svg class=\"lucide lucide-maximize2 lucide-maximize-2\" fill=\"none\" height=\"20\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" viewbox=\"0 0 24 24\" width=\"20\" xmlns=\"http://www.w3.org/2000/svg\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\"><a href=\"https://www.amazon.com/Machine-Learning-AI-Essential-Questions/dp/1718503768\">Machine Learning Q and AI book</a></figcaption></figure></div><p></p><p>Ahead of AI is a personal passion project that does not offer direct compensation, and I’d appreciate your support.</p><p>If you got the book, a review on Amazon would be really appreciated, too!</p><p></p>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42d277d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Ahead of AI\"\n",
    "Path(f'post_content/{name}').mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "with open(f\"post_content/{name}/{metadata[\"slug\"]}.html\", 'w', encoding='utf-8') as f:\n",
    "    f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee093e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(f\"post_content/{name}/{metadata[\"slug\"]}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eff742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Discussing the Latest Model Releases and AI Research in April 2024\\n\\nApril 2024, what a month! My birthday, a new book release, spring is finally here, and four major open LLM releases: Mixtral, Meta AI\\'s Llama 3, Microsoft\\'s Phi-3, and Apple\\'s OpenELM.\\n\\nThis article reviews and discusses all four major transformer-based LLM model releases that have been happening in the last few weeks, followed by new research on reinforcement learning with human feedback methods for instruction finetuning using PPO and DPO algorithms.\\n\\n1. How Good are Mixtral, Llama 3, and Phi-3?\\n\\n2. OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework\\n\\n3. Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study\\n\\n4. Other Interesting Research Papers In April\\n\\nFirst, let\\'s start with the most prominent topic: the new major LLM releases this month. This section will briefly cover Mixtral, Llama 3, and Phi-3, which have been accompanied by short blog posts or short technical papers. The next section will cover Apple\\'s OpenELM in a bit more detail, which thankfully comes with a research paper that shares lots of interesting details.\\n\\nMixtral 8x22B is the latest mixture-of-experts (MoE) model by Mistral AI, which has been released under a permissive Apache 2.0 open-source license.\\n\\nSimilar to the Mixtral 8x7B released in January 2024, the key idea behind this model is to replace each feed-forward module in a transformer architecture with 8 expert layers. It\\'s going to be a relatively long article, so I am skipping the MoE explanations, but if you are interested, the Mixtral 8x7B section in an article I shared a few months ago is a bit more detailed:\\n\\nThe perhaps most interesting plot from the Mixtral blog post, which compares Mixtral 8x22B to several LLMs on two axes: modeling performance on the popular Measuring Massive Multitask Language Understanding (MMLU) benchmark and active parameters (related to computational resource requirements).\\n\\nMeta AI\\'s first Llama model release in February 2023 was a big breakthrough for openly available LLM and was a pivotal moment for open(-source) LLMs. So, naturally, everyone was excited about the Llama 2 release last year. Now, the Llama 3 models, which Meta AI has started to roll out, are similarly exciting.\\n\\nWhile Meta is still training some of their largest models (e.g., the 400B variant), they released models in the familiar 8B and 70B size ranges. And they are good! Below, I added the MMLU scores from the official Llama 3 blog article to the Mixtral plot I shared earlier.\\n\\nOverall, the Llama 3 architecture is almost identical to Llama 2. The main differences are the increased vocabulary size and the fact that Llama 3 also uses grouped-query attention for the smaller-sized model. If you are looking for a grouped-query attention explainer, I\\'ve written about it here:\\n\\nBelow are the configuration files used for implementing Llama 2 and Llama 3 in LitGPT, which help show the main differences at a glance.\\n\\n**Training data size**\\n\\nThe main contributor to the substantially better performance compared to Llama 2 is the much larger dataset. Llama 3 was trained on 15 trillion tokens, as opposed to \"only\" 2 trillion for Llama 2.\\n\\nThis is a very interesting finding because, as the Llama 3 blog post notes, according to the Chinchilla scaling laws, the optimal amount of training data for an 8 billion parameter model is much smaller, approximately 200 billion tokens. Moreover, the authors of Llama 3 observed that both the 8 billion and 70 billion parameter models demonstrated log-linear improvements even at the 15 trillion scale. This suggests that we (that is, researchers in general) could further enhance the model with more training data beyond 15 trillion tokens.\\n\\n**Instruction finetuning and alignment**\\n\\nFor instruction finetuning and alignment, researchers usually choose between using reinforcement learning with human feedback (RLHF) via proximal policy optimization (PPO) or the reward-model-free direct preference optimization (DPO). Interestingly, the Llama 3 researchers did not favor one over the other; they used both! (More on PPO and DPO in a later section.)\\n\\nThe Llama 3 blog post stated that a Llama 3 research paper would follow in the coming month, and I am looking forward to the additional details that will hopefully be shared in this article.\\n\\nJust one week after the big Llama 2 release, Microsoft shared their new Phi-3 LLM. According to the benchmarks in the technical report, even the smallest Phi-3 model outperforms the Llama 3 8B model despite being less than half its size.\\n\\nNotably, Phi-3, which is based on the Llama architecture, has been trained on 5x fewer tokens than Llama 3 (3.3 trillion instead of 15 trillion). Phi-3 even uses the same tokenizer with a vocabulary size of 32,064 as Llama 2, which is much smaller than the Llama 3 vocabulary size.\\n\\nAlso, Phi-3-mini has \"only\" 3.8 billion parameters, which is less than half the size of Llama 3 8B.\\n\\nSo, What is the secret sauce? According to the technical report, it\\'s dataset quality over quantity: \"heavily filtered web data and synthetic data\".\\n\\nThe paper didn\\'t go into too much detail regarding the data curation, but it largely follows the recipe used for previous Phi models. I wrote more about Phi models a few months ago here:\\n\\nAs of this writing, people are still unsure whether Phi-3 is really as good as promised. For instance, many people I talked to noted that Phi-3 is much worse than Llama 3 for non-benchmark tasks.\\n\\nBased on the three major releases described above, this has been an exceptional month for openly available LLMs. And I haven\\'t even talked about my favorite model, OpenELM, which is discussed in the next section.\\n\\nWhich model should we use in practice? I think all three models above are attractive for different reasons. Mixtral has a lower active-parameter count than Llama 3 70B but still maintains a pretty good performance level. Phi-3 3.8B may be very appealing for mobile devices; according to the authors, a quantized version of it can run on an iPhone 14. And Llama 3 8B might be the most interesting all-rounder for fine-tuning since it can be comfortably fine-tuned on a single GPU when using LoRA.\\n\\nOpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework is the latest LLM model suite and paper shared by researchers at Apple, aiming to provide small LLMs for deployment on mobile devices.\\n\\nSimilar to the OLMo, it\\'s refreshing to see an LLM paper that shares details discussing the architecture, training methods, and training data.\\n\\nLet\\'s start with the most interesting tidbits:\\n\\nOpenELM comes in 4 relatively small and convenient sizes: 270M, 450M, 1.1B, and 3B\\n\\nFor each size, there\\'s also an instruct-version available trained with rejection sampling and direct preference optimization\\n\\nOpenELM performs slightly better than OLMo even though it\\'s trained on 2x fewer tokens\\n\\nThe main architecture tweak is a layer-wise scaling strategy\\n\\nBesides the layer-wise scaling strategy (more details later), the overall architecture settings and hyperparameter configuration are relatively similar to other LLMs like OLMo and Llama, as summarized in the figure below.\\n\\nSharing details is different from explaining them as research papers aimed to do when I was a student. For instance, they sampled a relatively small subset of 1.8T tokens from various public datasets (RefinedWeb, RedPajama, The PILE, and Dolma). This subset was 2x smaller than Dolma, which was used for training OLMo. But what was the rationale for this subsampling, and what were the sampling criteria?\\n\\nOne of the authors kindly followed up with me on that saying \"Regarding dataset: We did not have any rationale behind dataset sampling, except we wanted to use public datasets of about 2T tokens (following LLama2).\"\\n\\nThe layer-wise scaling strategy (adopted from the DeLighT: Deep and Light-weight Transformer paper) is very interesting. Essentially, the researchers gradually widen the layers from the early to the later transformer blocks. In particular, keeping the head size constant, the researchers increase the number of heads in the attention module. They also scale the hidden dimension of the feed-forward module, as illustrated in the figure below.\\n\\nI wish there was an ablation study training an LLM with and without the layer-wise scaling strategy on the same dataset. But those experiments are expensive, and I can understand why it wasn\\'t done.\\n\\nHowever, we can find ablation studies in the DeLighT: Deep and Light-weight Transformer paper that first introduced the layer-wise scaling on a smaller dataset based on the original encoder-decoder architecture, as shown below.\\n\\nAn interesting bonus I didn\\'t expect was that the researchers compared LoRA and DoRA (which I discussed a few weeks ago) for parameter-efficient finetuning! It turns out that there wasn\\'t a noticeable difference between the two methods, though.\\n\\nWhile the paper doesn\\'t answer any research questions, it\\'s a great, transparent write-up of the LLM implementation details. The layer-wise scaling strategy might be something that we could see more often in LLMs from now on. Also, the paper is only one part of the release. For further details, Apple also shared the OpenELM code on GitHub.\\n\\nAnyways, great work, and big kudos to the researchers (and Apple) for sharing!\\n\\n*Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study* finally answers one of the key questions I\\'ve been raising in previous months.\\n\\nLet\\'s start with a brief overview before diving into the results: Both PPO (proximal policy optimization) and DPO (direct preference optimization) are popular methods for aligning LLMs via reinforcement learning with human feedback (RLHF).\\n\\nRLHF is a key component of LLM development, and it\\'s used to align LLMs with human preferences, for example, to improve the safety and helpfulness of LLM-generated responses.\\n\\nFor a more detailed explanation and comparison, also see the *Evaluating Reward Modeling for Language Modeling section* in my Tips for LLM Pretraining and Evaluating Reward Models article that I shared last month.\\n\\nRLHF-PPO, the original LLM alignment method, has been the backbone of OpenAI\\'s InstructGPT and the LLMs deployed in ChatGPT. However, the landscape has shifted in recent months with the emergence of DPO-finetuned LLMs, which have made a significant impact on public leaderboards. This surge in popularity can be attributed to DPO\\'s reward-free alternative, which is notably easier to use: Unlike PPO, DPO doesn\\'t require training a separate reward model but uses a classification-like objective to update the LLM directly.\\n\\nToday, most LLMs on top of public leaderboards have been trained with DPO rather than PPO. Unfortunately, though, there have not been any direct head-to-head comparisons where the same model was trained with either PPO or DPO using the same dataset until this new paper came along.\\n\\n*Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study* is a well-written paper with lots of experiments and results, but the main takeaways are that PPO is generally better than DPO, and DPO suffers more heavily from out-of-distribution data.\\n\\nHere, out-of-distribution data means that the LLM has been previously trained on instruction data (using supervised finetuning) that is different from the preference data for DPO. For example, an LLM has been trained on the general Alpaca dataset before being DPO-finetuned on a different dataset with preference labels. (One way to improve DPO on out-of-distribution data is to add a supervised instruction-finetuning round on the preference dataset before following up with DPO finetuning).\\n\\nThe main findings are summarized in the figure below.\\n\\nIn addition to the main results above, the paper includes several additional experiments and ablation studies that I recommend checking out if you are interested in this topic.\\n\\nFurthermore, interesting takeaways from this paper include best-practice recommendations when using DPO and PPO.\\n\\nFor instance, if you use DPO, make sure to perform supervised finetuning on the preference data first. Also, iterative DPO, which involves labeling additional data with an existing reward model, is better than DPO on the existing preference data.\\n\\nIf you use PPO, the key success factors are large batch sizes, advantage normalization, and parameter updates via an exponential moving average.\\n\\nBased on this paper\\'s results, PPO seems superior to DPO if used correctly. However, given that DPO is more straightforward to use and implement, I expect DPO to remain a popular go-to method.\\n\\nA good practical recommendation may be to use PPO if you have ground truth reward labels (so you don\\'t have to pretrain your own reward model) or if you can download an in-domain reward model. Otherwise, use DPO for simplicity.\\n\\nAlso, based on what we know from the LLama 3 blog post, we don\\'t have to decide whether to use PPO or DPO, but we can use both! For instance, the recipe behind Llama 3 has been the following pipeline: Pretraining → supervised finetuning → rejection sampling → PPO → DPO. (I am hoping the Llama 3 developers will share a paper with more details soon!)\\n\\nOne of the best ways to understand LLMs is to code one from scratch!\\n\\nIf you are interested in learning more about LLMs, I am covering, implementing, and explaining the whole LLM lifecycle in my \"Build a Large Language Model from Scratch\" book, which is currently available at a discounted price before it is published in Summer 2024.\\n\\nChapter 5, which covers the pretraining, was just released 2 weeks ago. If this sounds interesting and useful to you, you can take a sneak peak at the code on GitHub here.\\n\\nBelow is a selection of other interesting papers I stumbled upon this month. Even compared to strong previous months, I think that LLM research in April has been really exceptional.\\n\\n**KAN: Kolmogorov–Arnold Networks** by Liu, Wang, Vaidya, *et al.* (30 Apr), https://arxiv.org/abs/2404.19756\\n\\nKolmogorov-Arnold Networks (KANs), which replace linear weight parameters with learnable spline-based functions on edges and lack fixed activation functions, seem to offer an attractive new alternative to Multi-Layer Perceptrons, which they outperform in accuracy, neural scaling, and interpretability.\\n\\n**When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively** by Labruna, Ander Campos, and Azkune (30 Apr), https://arxiv.org/abs/2404.19705\\n\\nThis paper proposes a custom training approach for LLMs that teaches them to either utilize their parametric memory or an external information retrieval system via a special token <RET> when it doesn\\'t know the answer.\\n\\n**A Primer on the Inner Workings of Transformer-based Language Models** by Ferrando, Sarti, Bisazza, and Costa-jussa (30 Apr), https://arxiv.org/abs/2405.00208\\n\\nThis primer offers a succinct technical overview of the techniques used to interpret Transformer-based, decoder-only language models\\n\\n**RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing** by Hu and Lu (30 Apr), https://arxiv.org/abs/2404.19543\\n\\nThis survey provides a comprehensive view of retrieval-augmented LLMs, detailing their components, structures, applications, and evaluation methods\\n\\n**Better & Faster Large Language Models via Multi-token Prediction** by Gloeckle, Idrissi, Rozière, *et al.* (30 Apr), https://arxiv.org/abs/2404.19737\\n\\nThis paper suggests that training LLMs to predict multiple future tokens simultaneously rather than just the next token not only improves sample efficiency but also improves performance on generative tasks.\\n\\n**LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report** by Zhao, Wang, Abid, *et al.* (28 Apr), https://arxiv.org/abs/2405.00732\\n\\nLoRA is one of the most wide parameter-efficient finetuning techniques, and this study finds that 4-bit LoRA finetuned models significantly outperform both their base models and GPT-4.\\n\\n**Make Your LLM Fully Utilize the Context**, An, Ma, Lin *et al.* (25 Apr), https://arxiv.org/abs/2404.16811\\n\\nThe study introduces FILM-7B, a model trained using an information-intensive approach to address the \"lost-in-the-middle\" challenge, which describes the problem where LLMs are not able to retrieve information if it\\'s not at the beginning or end of the context window.\\n\\n**Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding** by Elhoushi, Shrivastava, Liskovich, *et al.* (25 Apr), https://arxiv.org/abs/2404.16710\\n\\nLayerSkip can accelerate the inference of LLMs by using layer dropout and early exit loss during training, and implementing self-speculative decoding during inference.\\n\\n**Retrieval Head Mechanistically Explains Long-Context Factuality** by Wu, Wang, Xiao, *et al.* (24 Apr), https://arxiv.org/abs/2404.15574\\n\\nThis paper explores how transformer-based models with long-context capabilities use specific \"retrieval heads\" in their attention mechanisms to effectively retrieve information, revealing that these heads are universal, sparse, intrinsic, dynamically activated, and crucial for tasks requiring reference to prior context or reasoning.\\n\\n**Graph Machine Learning in the Era of Large Language Models (LLMs)** by Fan, Wang, Huang, *et al.* (23 Apr), https://arxiv.org/abs/2404.14928\\n\\nThis survey paper describes, among others, how Graph Neural Networks and LLMs are increasingly integrated to improve graph machine learning and reasoning capabilities.\\n\\n**NExT: Teaching Large Language Models to Reason about Code Execution** by Ni, Allamanis, Cohan, *et al.* (23 Apr), https://arxiv.org/abs/2404.14662\\n\\nNExT is a method to improve how LLMs understand and fix code by teaching them to analyze program execution.\\n\\n**Multi-Head Mixture-of-Experts** by Wu, Huang, Wang, and Wei (23 Apr), https://arxiv.org/abs/2404.15045\\n\\nThe proposed Multi-Head Mixture-of-Experts (MH-MoE) model addresses Sparse Mixtures of Experts\\' issues of low expert activation and poor handling of multiple semantic concepts by introducing a multi-head mechanism that splits tokens into sub-tokens processed by diverse experts in parallel.\\n\\n**A Survey on Self-Evolution of Large Language Models** by Tao, Lin, Chen, *et al.* (22 Apr), https://arxiv.org/abs/2404.14662\\n\\nThis work presents a comprehensive survey of self-evolution approaches in LLMs, proposing a conceptual framework for LLM self-evolution and identifying challenges and future directions to enhance these models\\' capabilities.\\n\\n**OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework** by Mehta, Sekhavat, Cao *et al.* (22 Apr), https://arxiv.org/abs/2404.14619\\n\\nOpenELM by researchers from Apple is a LLM suite by Apple in the spirit of OLMo (a model family I covered previously), including full training and evaluation frameworks, logs, checkpoints, configurations, and other artifacts for reproducible research.\\n\\n**Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone** by Abdin, Jacobs, Awan, *et al.* (Apr 22), https://arxiv.org/abs/2404.14219\\n\\nPhi-3-mini is a 3.8 billion parameter LLM trained on 3.3 trillion tokens that matches the performance of larger models like Mixtral 8x7B and GPT-3.5 according to benchmarks.\\n\\n**How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study** by Huang, Ma, and Qin (22 Apr), https://arxiv.org/abs/2404.14047\\n\\nThis empirical study finds that Meta\\'s LLaMA3 model reveals significant performance degradation at ultra-low bit-widths.\\n\\n**The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions** by Wallace, Xiao, Leike, *et al.* (19 Apr), https://arxiv.org/abs/2404.13208\\n\\nThis study introduces an instruction hierarchy for LLMs to prioritize trusted prompts, enhancing their robustness against attacks without compromising their standard capabilities.\\n\\n**OpenBezoar: Small, Cost-Effective and Open Models Trained on Mixes of Instruction Data** by Dissanayake, Lowe, Gunasekara, and Ratnayake (18 Apr), https://arxiv.org/abs/2404.12195\\n\\nThe research finetunes the OpenLLaMA 3Bv2 model using synthetic data from Falcon-40B and techniques like RLHF and DPO, achieving top performance in LLM tasks at a reduced model size by systematically filtering and finetuning data.\\n\\n**Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing** by Tian, Peng, Song,* et al.* (18 Apr), https://arxiv.org/abs/2404.12253\\n\\nDespite the impressive capabilities of LLMs in various tasks, they struggle with complex reasoning and planning; the proposed AlphaLLM integrates Monte Carlo Tree Search to create a self-improving loop, enhancing LLMs\\' performance in reasoning tasks without additional data annotations.\\n\\n**When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes** by Yehudai and Bendel (18 Apr), https://arxiv.org/abs/2404.12365\\n\\nFastFit is a new Python package that rapidly and accurately handles few-shot classification for language tasks with many similar classes by integrating batch contrastive learning and token-level similarity scoring, showing a 3-20x increase in training speed and superior performance over other methods like SetFit and HF Transformers.\\n\\n**A Survey on Retrieval-Augmented Text Generation for Large Language Models** by Huang and Huang (17 Apr), https://arxiv.org/abs/2404.10981\\n\\nThis survey article discusses how Retrieval-Augmented Generation (RAG) combines retrieval techniques and deep learning to improve LLMs by dynamically incorporating up-to-date information, categorizes the RAG process, reviews recent developments, and proposes future research directions\\n\\n**How Faithful Are RAG Models? Quantifying the Tug-of-War Between RAG and LLMs\\' Internal Prior** by Wu, Wu, and Zou (16 Apr), https://arxiv.org/abs/2404.10198\\n\\nProviding correct retrieved information generally corrects errors in large language models like GPT-4, but incorrect information is often repeated unless countered by strong internal knowledge.\\n\\n**Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies **by Li, Xie, and Cubuk (16 Apr), https://arxiv.org/abs/2404.08197\\n\\nThis paper explores the scaling down of Contrastive Language-Image Pretraining (CLIP) to fit limited computational budgets, demonstrating that high-quality, smaller datasets often outperform larger, lower-quality ones, and that smaller ViT models are optimal for these datasets.\\n\\n**Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study** by Xu, Fu, Gao *et al.* (16 Apr), https://arxiv.org/abs/2404.10719\\n\\nThis research explores the effectiveness of Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO) in Reinforcement Learning from Human Feedback (RLHF), finding that PPO can to surpass all other alternative methods in all cases if applied properly.\\n\\n**Learn Your Reference Model for Real Good Alignment** by Gorbatovski, Shaposhnikov, Malakhov, *et al.* (15 Apr), https://arxiv.org/abs/2404.09656\\n\\nThe research highlights that the new alignment method, Trust Region Direct Preference Optimization (TR-DPO), which updates the reference policy during training, outperforms existing techniques by improving model quality across multiple parameters, demonstrating up to a 19% improvement on specific datasets.\\n\\n**Chinchilla Scaling: A Replication Attempt** by Besiroglu, Erdil, Barnett, and You (15 Apr), https://arxiv.org/abs/2404.10102\\n\\nThe authors attempt to replicate one of Hoffmann et al.\\'s methods for estimating compute-optimal scaling laws, finding inconsistencies and implausible results compared to the original estimates from other methods.\\n\\n**State Space Model for New-Generation Network Alternative to Transformers: A Survey** by Wang, Wang, Ding, *et al.* (15 Apr), https://arxiv.org/abs/2404.09516\\n\\nThe paper provides a comprehensive review and experimental analysis of State Space Models (SSM) as an efficient alternative to the Transformer architecture, detailing the principles of SSM, its applications across diverse domains, and offering statistical comparisons to demonstrate its advantages and potential areas for future research.\\n\\n**LLM In-Context Recall is Prompt Dependent** by Machlab and Battle (13 Apr), https://arxiv.org/abs/2404.08865\\n\\nThe research assesses the in-context recall ability of various LLMs by embedding a factoid within a block of text and evaluating the models\\' performance in retrieving this information under different conditions, revealing that performance is influenced by both the prompt content and potential biases in training data.\\n\\n**Dataset Reset Policy Optimization for RLHF** by Chang, Zhan, Oertell, et al. (12 Apr), https://arxiv.org/abs/2404.08495\\n\\nThis work introduces Dataset Reset Policy Optimization (DR-PO), a new Reinforcement Learning from Human Preference-based feedback (RLHF) algorithm that enhances training by integrating an offline preference dataset directly into the online policy training.\\n\\n**Pre-training Small Base LMs with Fewer Tokens** by Sanyal, Sanghavi, and Dimakis (12 Apr), https://arxiv.org/abs/2404.08634\\n\\nThe study introduces \"Inheritune,\" a method for developing smaller base language models by inheriting a few transformer blocks from larger models and training on a tiny fraction of the larger model\\'s data, demonstrating that these smaller models perform comparably to larger models despite using significantly less training data and resources.\\n\\n**Rho-1: Not All Tokens Are What You Need** by Lin, Gou, Gong *et al.*, (11 Apr), https://arxiv.org/abs/2404.07965\\n\\nRho-1 is a new language model that is trained selectively on tokens that demonstrate higher excess loss as opposed to traditional next-token prediction methods.\\n\\n**Best Practices and Lessons Learned on Synthetic Data for Language Models** by Liu, Wei, Liu, *et al.* (11 Apr), https://arxiv.org/abs/2404.07503\\n\\nThis paper reviews synthetic data research in the context of LLMs.\\n\\n**JetMoE: Reaching Llama2 Performance with 0.1M Dollars**, Shen, Guo, Cai, and Qin (11 Apr), https://arxiv.org/abs/2404.07413\\n\\nJetMoE-8B, an 8-billion parameter, sparsely-gated Mixture-of-Experts model trained on 1.25 trillion tokens for under $100,000, outperforms more expensive models such as Llama2-7B by using only 2 billion parameters per input token and \"only\" 30,000 GPU hours.\\n\\n**LLoCO: Learning Long Contexts Offline** by Tan, Li, Patil *et al.* (11 Apr), https://arxiv.org/abs/2404.07979\\n\\nLLoCO is a method combining context compression, retrieval, and parameter-efficient finetuning with LoRA to effectively expand the context window of a LLaMA2-7B model to handle up to 128k tokens\\n\\n**Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention** by Munkhdalai, Faruqui, and Gopal (10 Apr), https://arxiv.org/abs/2404.07143\\n\\nThis research introduces a method to scale transformer-based LLMs for processing infinitely long inputs efficiently by combining several attention strategies within a single transformer block for tasks with extensive contextual demands.\\n\\n**Adapting LLaMA Decoder to Vision Transformer** by Wang, Shao, Chen, *et al.* (10 Apr), https://arxiv.org/abs/2404.06773\\n\\nThis research adapts decoder-only transformer-based LLMs like Llama for computer vision by modifying a standard vision transformer (ViT) with techniques like a post-sequence class token and a soft mask strategy.\\n\\n**LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders** by BehnamGhader, Adlakha, Mosbach, *et al.* (9 Apr), https://arxiv.org/abs/2404.05961\\n\\nThis research introduces a simple, unsupervised approach to transform decoder-style LLMs (like GPT and Llama) into strong text encoders via 1) disabling the causal attention mask, 2) masked next token prediction, and 3) unsupervised contrastive learning.\\n\\n**Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models** by Bordt, Nori, Rodrigues, *et al*. (9 Apr), https://arxiv.org/abs/2404.06209\\n\\nThis study highlights critical issues of data contamination and memorization in LLMs, showing that LLMs often memorize popular tabular datasets and perform better on datasets seen during training, which leads to overfitting\\n\\n**MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies** by Hu, Tu, Han, *et al. *(9 Apr), https://arxiv.org/abs/2404.06395\\n\\nThis research introduces new resource-efficient \"small\" language models in the 1.2-2.4 billion parameter range, along with techniques such as the warmup-stable-decay learning rate scheduler, which is helpful for continuous pretraining and domain adaptation.\\n\\n**CodecLM: Aligning Language Models with Tailored Synthetic Data** by Wang, Li, Perot, *et al*. (8 Apr), https://arxiv.org/abs/2404.05875\\n\\nCodecLM introduces a framework using encode-decode principles and LLMs as codecs to adaptively generate high-quality synthetic data for aligning LLMs with various instruction distributions to improve their ability to follow complex, diverse instructions.\\n\\n**Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence** by Peng, Goldstein, Anthony, *et al.* (8 Apr), https://arxiv.org/abs/2404.05892\\n\\nEagle and Finch are new sequence models based on the RWKV architecture, introducing features like multi-headed matrix states and dynamic recurrence.\\n\\n**AutoCodeRover: Autonomous Program Improvement** by Zhang, Ruan, Fan, and Roychoudhury (8 Apr), https://arxiv.org/abs/2404.05427\\n\\nAutoCodeRover is an automated approach utilizing LLMs and advanced code search to solve GitHub issues by modifying software programs.\\n\\n**Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation** by Wan, Wang, Yong, *et al.* (5 Apr), https://arxiv.org/abs/2404.04256\\n\\nSigma is an approach to multi-modal semantic segmentation using a Siamese Mamba (structure state space model) network, which combines different modalities like thermal and depth with RGB and presents an alternative to CNN- and vision transformer-based approaches.\\n\\n**Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data** by Zhang, Marone, Li, *et al.* (5 Apr 2024), https://arxiv.org/abs/2404.03862\\n\\nQuote-Tuning improves the trustworthiness and accuracy of large language models by training them to increase verbatim quoting from reliable sources by 55% to 130% compared to standard models.\\n\\n**ReFT: Representation Finetuning for Language Models** by Wu, Arora, Wang, et al. (5 Apr), https://arxiv.org/abs/2404.03592\\n\\nThis paper introduces Representation Finetuning (ReFT) methods, analogous to parameter-efficient finetuning (PEFT), for adapting large models efficiently by modifying only their hidden representations rather than the full set of parameters.\\n\\n**CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues** by Sreedhar, Rebedea, Ghosh, and Parisien (4 Apr), https://arxiv.org/abs/2404.03820\\n\\nThis paper introduces the CantTalkAboutThis dataset, which is designed to help LLMs stay on topic during task-oriented conversations (it includes synthetic dialogues across various domains, featuring distractor turns to challenge and train models to resist topic diversion).\\n\\n**Training LLMs over Neurally Compressed Text** by Lester, Lee, Alemi, *et al.* (4 Apr), https://arxiv.org/abs/2404.03626\\n\\nThis paper introduces a method for training LLMs on neurally compressed text (text compressed by a small language model) using Equal-Info Windows, a technique that segments text into blocks of equal bit length,\\n\\n**Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences** by Andriushchenko, Croce, and Flammarion (4 Apr), https://arxiv.org/abs/2404.02151\\n\\nThis paper introduces Direct Nash Optimization (DNO), a post-training method for LLMs that uses preference feedback from an oracle to iteratively improve model performance as alternative to other reinforcement learning with human feedback (RLHF) approaches.\\n\\n**Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models** by Zhang, Liu, Xie, *et al.* (3 Apr), https://arxiv.org/abs/2404.02747\\n\\nThe study looks into how cross-attention functions in text-conditional diffusion models during inference, discovers that it stabilizes at a certain point, and finds that bypassing text inputs after this convergence point simplifies the process without compromising on output quality.\\n\\n**BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models** by Luo, Hengzu, and Li (3 Apr), https://arxiv.org/abs/2404.02827\\n\\nBAdam is a memory-efficient optimizer that improves the efficiency of finetuning LLMs, which is also easy to use and comes with only one additional hyperparameter.\\n\\n**On the Scalability of Diffusion-based Text-to-Image Generation** by Li, Zou, Wang, *et al.* (3 Apr), https://arxiv.org/abs/2404.02883\\n\\nThis study empirically investigates the scaling properties of diffusion-based text-to-image models by analyzing the effects of scaling denoising backbones and training sets, uncovering that the efficiency of cross-attention and transformer blocks significantly influences performance, and identifying strategies for enhancing text-image alignment and learning efficiency at lower costs.\\n\\n**Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks** by Andriushchenko, Croce, and Flammarion (2 Apr), https://arxiv.org/abs/2404.02151\\n\\nThis study reveals that even the latest safety-focused LLMs can be easily jailbroken using adaptive techniques, achieving nearly 100% success across various models through methods like adversarial prompting, exploiting API vulnerabilities, and token search space restriction.\\n\\n**Emergent Abilities in Reduced-Scale Generative Language Models** by Muckatira, Deshpande, Lialin, and Rumshisky (2 Apr), https://arxiv.org/abs/2404.02204\\n\\nThis study finds that very \"small\" LLMs (from 1 to 165 million parameters) can also exhibit emergent properties if the dataset for pretraining is scaled down and simplified.\\n\\n**Long-context LLMs Struggle with Long In-context Learning** by Li, Zheng, Do, *et al. *(2 Apr), https://arxiv.org/abs/2404.02060\\n\\nLIConBench, a new benchmark focusing on long in-context learning and extreme-label classification, reveals that while LLMs excel up to 20K tokens, their performance drops in longer sequences, with GPT-4 being an exception, highlighting a gap in processing extensive context-rich information.\\n\\n**Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models** by Raposo, Ritter, Richard *et al.* (2 Apr), https://arxiv.org/abs/2404.02258\\n\\nThis research introduces a method for transformer-based language models to dynamically allocate computational resources (FLOPs) across different parts of an input sequence, optimizing performance and efficiency by selecting specific tokens for processing at each layer.\\n\\n**Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models** by Fei, Fan, Yu, et al. (6 Apr), https://arxiv.org/abs/2404.04478\\n\\nThis paper introduces Diffusion-RWKV, an adaptation of the RWKV architecture from NLP for diffusion models in image generation.\\n\\n**The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis** by Yang, Li, Niu, *et al.* (1 Apr), https://arxiv.org/abs/2404.01204\\n\\nThis research identifies early-stage capable of predicting the eventual LLMs, which is helpful analyzing LLMs during pretraining and improving the pretraining setup.\\n\\n**Bigger is not Always Better: Scaling Properties of Latent Diffusion Models** by Mei, Tu, Delbracio, *et al.* (1 Apr), https://arxiv.org/abs/2404.01367\\n\\nThis study explores how the size of latent diffusion models affects sampling efficiency across different steps and tasks, revealing that smaller models often produce higher quality results within a given inference budget.\\n\\n**Do Language Models Plan Ahead for Future Tokens?** by Wu, Morris, and Levine (1 Apr), https://arxiv.org/abs/2404.00859\\n\\nThe research paper finds empirical evidence that transformers anticipate future information during inference through \"pre-caching\" and \"breadcrumbs\" mechanisms.\\n\\nIf you are looking for a book that explains intermediate to advanced topics in machine learning and AI in a focused manner, you might like my book, \"Machine Learning Q and AI.\" The print version was just released two weeks ago!\\n\\nAhead of AI is a personal passion project that does not offer direct compensation, and I’d appreciate your support.\\n\\nIf you got the book, a review on Amazon would be really appreciated, too!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_convert(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f95aca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:html_reader:Found 31 HTML files\n",
      "INFO:html_reader:Successfully converted 31/31 files\n"
     ]
    }
   ],
   "source": [
    "batch_convert('post_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf6eeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter = newsletters[\"Sustainability by numbers\"]\n",
    "posts = newsletter.get_posts(sorting='new', limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af1af7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Post(url=https://www.sustainabilitybynumbers.com/p/iea-current-policies-scenario),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/global-carbon-emissions-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/amazon-deforestation-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/artificial-intelligence-could-dramatically),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/usa-electricity-growth),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/eliminating-contrails),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/food-projections-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/clearing-the-air-published-uk),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/the-electrotech-revolution),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/solar-wind-speed-rollout),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/ai-footprint-august-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/electric-car-battery-degradation),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/agricultural-total-factor-productivity),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/population-growth-decline-climate),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/clearing-the-air-announcement),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/geothermal-energy),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/generational-gap-climate),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/reflections-on-substack),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/wild-mammals-vs-meat),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/china-cheap-solar-batteries),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/carbon-footprint-chatgpt),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/clean-energy-imports-jobs),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/used-electric-car-costs),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/whale-carbon-capture),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/uk-ccc-seventh-budget),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/wildfires-2024),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/season-2-solving-for-climate),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/us-states-electricity-sources-prices),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/us-states-electricity-2025),\n",
       " Post(url=https://www.sustainabilitybynumbers.com/p/how-many-people-died-in-disasters)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c9ea154",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = posts[0]\n",
    "metadata = post.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b83cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>“Yes” was what many media outlets reported last week.</p><p>Take a look at the headline clippings below (from the <a href=\"https://www.ft.com/content/8696254d-1873-434a-96be-88aa690f9b75\">Financial Times</a>, <a href=\"https://www.wsj.com/articles/ieas-revived-policy-outlook-sees-no-peak-in-oil-gas-demand-this-decade-50939014\">Wall Street Journal</a>, <a href=\"https://www.offshore-technology.com/news/iea-oil-and-gas-consumption-prediction/\">Offshore Technology</a>, and <a href=\"https://www.telegraphindia.com/business/iea-projects-oil-demand-to-rise-till-2050-with-india-leading-global-consumption-growth-prnt/cid/2132616\">Telegraph India</a>). There were <a href=\"https://www.bloomberg.com/news/articles/2025-11-12/iea-reinstates-bullish-oil-demand-growth-scenario-in-key-report\">many more</a>.</p><p>These refer to the International Energy Agency’s newly published “<a href=\"https://www.iea.org/reports/world-energy-outlook-2025\">World Energy Outlook 2025</a>”. In this report, the IEA projects the evolution of global energy demand — and individual sources — in the coming decades under a number of <em><strong>scenarios </strong></em>(as we’ll see, this emphasis is important).</p><p>One of these, which was retired for a few years but has made a comeback, is the “Current Policies Scenario” (CPS). That’s the one that all of the headlines are referring to.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!uCfH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg\" width=\"960\" height=\"540\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ebf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:540,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1456w\" sizes=\"100vw\" fetchpriority=\"high\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Before we get into what this scenario actually entails — and think about whether it’s likely — it’s worth clarifying what the IEA means, or does not mean, by it. It is <a href=\"https://iea.blob.core.windows.net/assets/5306bae2-1f99-402f-8d14-542bfa0ae96e/WorldEnergyOutlook2025.pdf\">very clear</a> in its report that:</p><p><em>“The CPS is not a forecast or a prediction of the way the energy system will unfold. Nor should it be interpreted as a “business-as-usual” scenario.”</em></p><p>Again, it is a <em>scenario</em>. It is not a forecast or a prediction. So at least half of the headlines above are immediately incorrect. It might seem like I’m being pedantic on terminology (as are the IEA, since they dedicate <a href=\"https://www.iea.org/commentaries/scenarios-in-the-world-energy-outlook-2025\">entire articles</a> trying to clarify this), but these distinctions matter.</p><p>A scenario is basically a “what if” story. It makes a bunch of assumptions, and asks what the outcome will be — in terms of energy supplies, or CO<sub>2</sub> emissions — if those hold true. They’re useful in exploring what the future would look like if the world did x or y.</p><p>A forecast is more like a “best estimate” trajectory of what will happen based on current evidence and trends. You might call this an expected pathway.</p><p>A prediction is asserting what you think <em>will </em>happen.</p><p>The IEA’s CPS is not what it says <em>will</em> happen. Nor is it even what it thinks will be the most likely trajectory (a forecast). It simply models the outcome of what would happen based on a bunch of input assumptions. How closely these scenarios match someone’s predictions depends on how reasonable and likely they think those inputs are.</p><p>What are the CPS’s assumptions? It only includes changes driven by policies that are already written into law or regulation; it excludes future policy changes, even where governments have announced intentions. Other drivers — technology cost declines, economics, demographics — are still in the model, but they only move the system as far as today’s policies allow. For that reason, I think the CPS is incredibly pessimistic about the speed of the transition (or, rather, that there is even a transition at all).</p><p>Running several scenarios is incredibly useful for understanding how trends would evolve under different conditions. The problem is that these are often misinterpreted or miscommunicated. They can take on a whole new world of their own.</p><p>If you have no understanding of the assumptions underlying any scenario, it’s impossible to know how to treat them. Only by looking under the hood can we start to judge whether they seem likely or not.</p><p>Here, I wanted to make the CPS a bit more transparent and show what the IEA assumes in some key areas, specifically the rollout of electric vehicles, and the speed of solar PV deployment.</p><div><hr></div><h1><strong>The electric car rollout stalls everywhere but China and Europe</strong></h1><p>Many countries in the world don’t have existing policies or legislation in place that would dramatically shift EV adoption rates. They often also lack charging infrastructure to absorb more electric cars without expanding it. The CPS assumes that neither changes.</p><p>That means the only regions where EV sales <em>do </em>grow are in the European Union and China. As you can see in the chart below, they achieve nearly 100% EV sales by 2035. But in every other region, EV sales basically stall at their current level.</p><p>What this means at a global level is that the market share for EVs increases from 25% today to 40% in 2035. But then this share falls a bit through to 2050, as most cars will be sold in countries where EVs have somehow been stuck at a multi-decade hiatus.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!YH46!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 424w, https://substackcdn.com/image/fetch/$s_!YH46!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 848w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1272w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png\" width=\"707\" height=\"462.2692307692308\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:952,&quot;width&quot;:1456,&quot;resizeWidth&quot;:707,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 424w, https://substackcdn.com/image/fetch/$s_!YH46!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 848w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1272w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Source: International Energy Agency (2025). <a href=\"https://www.iea.org/reports/world-energy-outlook-2025\">World Energy Outlook 2025</a>.</figcaption></figure></div><p>Is this a reasonable assumption?</p><p>You be the judge. Take a look at the chart below, which shows the share of new cars that are electric in countries outside of the EU and China. Now imagine that those curves suddenly level off and never rise again. That’s what the CPS assumes.</p><p>I can’t tell you the pace of the global EV rollout. I also think that many countries will have temporary stalls in their EV sales for various reasons. Maybe we’ll see that in the US in the next few years. But given the historical rates of growth, the fact that electric cars continue to get better and cheaper, <em>and</em> national motivations to be free from the ups and downs of global oil markets, it seems implausible to me that all of these curves suddenly and permanently level off.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!EGy4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 424w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 848w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1272w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png\" width=\"701\" height=\"494.9368131868132\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1028,&quot;width&quot;:1456,&quot;resizeWidth&quot;:701,&quot;bytes&quot;:529590,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.sustainabilitybynumbers.com/i/179114194?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 424w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 848w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1272w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>If EV sales stalled across most of the world, and efficiency improvements in petrol cars dramatically slowed (which the IEA also assumes), then you will get a result that says that oil demand will continue to increase all the way through to 2050.</p><p>The point is not that we should never consider what this scenario might look like. It’s useful and important to know what might happen to the EV rollout absent of new policies <em>or</em> other market and technological forces driving things forward. But it’s crucial for people to know what it is that they’re looking at. Clearly, judging by the headlines and broader discussion, this is not the case.</p><div><hr></div><h1><strong>Global deployment of solar PV stalls at 2024 levels</strong></h1><p>Moving from transport to the electricity grid, another interesting assumption in the Current Policies Scenario is that solar photovoltaic (PV) deployment stalls at its 2024 levels for more than a decade.</p><p>As it states:</p><p><em>“Solar PV and wind continue to expand, but they face mounting integration challenges in the CPS in the absence of additional government policies, which slow their deployment. Annual solar PV capacity additions average 540 GW to 2035, holding steady at roughly the 2024 level, and halting the trend that has seen deployment rise ten-fold from 2015 to 2024.”</em></p><p>To provide some context for what this looks like, I’ve plotted the IEA’s <a href=\"https://www.iea.org/data-and-statistics/data-tools/renewable-energy-progress-tracker\">historical data</a> on solar PV deployment (in red) and added a line that shows future deployments stalling at 540 GW through to 2035.<a class=\"footnote-anchor\" data-component-name=\"FootnoteAnchorToDOM\" id=\"footnote-anchor-1\" href=\"#footnote-1\" target=\"_self\">1</a></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!rtOL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 424w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 848w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1272w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png\" width=\"695\" height=\"537.0020604395604\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1125,&quot;width&quot;:1456,&quot;resizeWidth&quot;:695,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 424w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 848w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1272w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Does this trend also seem reasonable?</p><p>It does repeat the pattern of <a href=\"https://www.pv-magazine.com/2018/11/20/iea-versus-solar-pv-reality\">now-infamous</a> “expectations vs. reality” solar PV chart, which was first produced by <a href=\"https://www.aukehoekstra.nl/\">Auke Hoekstra</a>. The IEA’s “policy scenarios” projected a stalling of global PV deployment as far back as 2006, but actual growth has consistently exceeded these expectations year after year.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!Wljd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 424w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 848w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1272w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png\" width=\"551\" height=\"455\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:455,&quot;width&quot;:551,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 424w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 848w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1272w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>I think the assumption that solar PV will top out at 2024 levels for more than a decade is overly conservative and pessimistic. I don’t think this will happen in the way it’s portrayed in the chart.</p><p>However, this assumption is not <em>quite</em> as bewildering as the one on electric vehicles. There is a reasonable discussion to be had about <em>when</em> global deployment rates start to slow. Solar deployment has undergone several “doublings” now. That curve probably doesn’t have many left in it. When China’s rates start to slow — which they eventually will — this will have a big impact on the global total. Even if deployment is going strong and continuing to rise in other low-to middle-income countries, they’re too small to pick up the “slack” from China’s slowed rates.</p><p>I still think it’s unlikely that we’re at peak solar PV deployment globally. Some might disagree.</p><p>That’s fine, and that’s the point of laying out some of the crucial underlying assumptions of these scenarios. You can judge what you think is realistic or not. But without this transparency, many are left with headlines like “<a href=\"https://www.offshore-technology.com/news/iea-oil-and-gas-consumption-prediction/\">IEA predicts increase in oil and gas consumption until 2050</a>”. This is <em>not</em> what the IEA predicts, because it does not provide predictions at all.</p><div><hr></div><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://www.sustainabilitybynumbers.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://www.sustainabilitybynumbers.com/subscribe?\"><span>Subscribe now</span></a></p><div class=\"footnote\" data-component-name=\"FootnoteToDOM\"><a id=\"footnote-1\" href=\"#footnote-anchor-1\" class=\"footnote-number\" contenteditable=\"false\" target=\"_self\">1</a><div class=\"footnote-content\"><p>I’ve summed the historical data for “PV distributed systems” and “PV utility-scale systems” for each year.<br><br>This has been unified by the IEA to direct current (DC).</p><p>https://www.iea.org/data-and-statistics/data-tools/renewable-energy-progress-tracker</p><p></p></div></div>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['body_html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed8cd6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audience', 'audience_before_archived', 'canonical_url', 'default_comment_sort', 'editor_v2', 'exempt_from_archive_paywall', 'free_unlock_required', 'id', 'podcast_art_url', 'podcast_duration', 'podcast_preview_upload_id', 'podcast_upload_id', 'podcast_url', 'post_date', 'updated_at', 'publication_id', 'search_engine_description', 'search_engine_title', 'section_id', 'should_send_free_preview', 'show_guest_bios', 'slug', 'social_title', 'subtitle', 'teaser_post_eligible', 'title', 'type', 'video_upload_id', 'write_comment_permissions', 'meter_type', 'live_stream_id', 'is_published', 'restacks', 'reactions', 'top_exclusions', 'pins', 'section_pins', 'has_shareable_clips', 'previous_post_slug', 'next_post_slug', 'cover_image', 'cover_image_is_square', 'cover_image_is_explicit', 'videoUpload', 'podcastFields', 'podcastUpload', 'podcastPreviewUpload', 'voiceover_upload_id', 'voiceoverUpload', 'has_voiceover', 'description', 'body_html', 'truncated_body_text', 'wordcount', 'postTags', 'postCountryBlocks', 'headlineTest', 'coverImagePalette', 'publishedBylines', 'reaction', 'reaction_count', 'comment_count', 'child_comment_count', 'audio_items', 'is_geoblocked', 'hasCashtag', 'unlockedWithIP', 'themeVariables', 'comments'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce6216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will oil and gas consumption keep rising through 2050?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd94eb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newsletter'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eeb2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = f\"\"\"<header>\n",
    "<h1>{metadata['title']}</h1>\n",
    "<p>{metadata['subtitle']}</p\n",
    "</header>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce5cefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_out = header + metadata['body_html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8a6e13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<header>\\n<h1>Will oil and gas consumption keep rising through 2050?</h1>\\n<p>Unpacking some of the assumptions behind the IEA\\'s policy scenarios.</p\\n</header>\\n<p>“Yes” was what many media outlets reported last week.</p><p>Take a look at the headline clippings below (from the <a href=\"https://www.ft.com/content/8696254d-1873-434a-96be-88aa690f9b75\">Financial Times</a>, <a href=\"https://www.wsj.com/articles/ieas-revived-policy-outlook-sees-no-peak-in-oil-gas-demand-this-decade-50939014\">Wall Street Journal</a>, <a href=\"https://www.offshore-technology.com/news/iea-oil-and-gas-consumption-prediction/\">Offshore Technology</a>, and <a href=\"https://www.telegraphindia.com/business/iea-projects-oil-demand-to-rise-till-2050-with-india-leading-global-consumption-growth-prnt/cid/2132616\">Telegraph India</a>). There were <a href=\"https://www.bloomberg.com/news/articles/2025-11-12/iea-reinstates-bullish-oil-demand-growth-scenario-in-key-report\">many more</a>.</p><p>These refer to the International Energy Agency’s newly published “<a href=\"https://www.iea.org/reports/world-energy-outlook-2025\">World Energy Outlook 2025</a>”. In this report, the IEA projects the evolution of global energy demand — and individual sources — in the coming decades under a number of <em><strong>scenarios </strong></em>(as we’ll see, this emphasis is important).</p><p>One of these, which was retired for a few years but has made a comeback, is the “Current Policies Scenario” (CPS). That’s the one that all of the headlines are referring to.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!uCfH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg\" width=\"960\" height=\"540\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ebf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:540,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!uCfH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 424w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 848w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!uCfH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febf9231e-c766-4c6d-a255-83cd98faddaa_960x540.jpeg 1456w\" sizes=\"100vw\" fetchpriority=\"high\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Before we get into what this scenario actually entails — and think about whether it’s likely — it’s worth clarifying what the IEA means, or does not mean, by it. It is <a href=\"https://iea.blob.core.windows.net/assets/5306bae2-1f99-402f-8d14-542bfa0ae96e/WorldEnergyOutlook2025.pdf\">very clear</a> in its report that:</p><p><em>“The CPS is not a forecast or a prediction of the way the energy system will unfold. Nor should it be interpreted as a “business-as-usual” scenario.”</em></p><p>Again, it is a <em>scenario</em>. It is not a forecast or a prediction. So at least half of the headlines above are immediately incorrect. It might seem like I’m being pedantic on terminology (as are the IEA, since they dedicate <a href=\"https://www.iea.org/commentaries/scenarios-in-the-world-energy-outlook-2025\">entire articles</a> trying to clarify this), but these distinctions matter.</p><p>A scenario is basically a “what if” story. It makes a bunch of assumptions, and asks what the outcome will be — in terms of energy supplies, or CO<sub>2</sub> emissions — if those hold true. They’re useful in exploring what the future would look like if the world did x or y.</p><p>A forecast is more like a “best estimate” trajectory of what will happen based on current evidence and trends. You might call this an expected pathway.</p><p>A prediction is asserting what you think <em>will </em>happen.</p><p>The IEA’s CPS is not what it says <em>will</em> happen. Nor is it even what it thinks will be the most likely trajectory (a forecast). It simply models the outcome of what would happen based on a bunch of input assumptions. How closely these scenarios match someone’s predictions depends on how reasonable and likely they think those inputs are.</p><p>What are the CPS’s assumptions? It only includes changes driven by policies that are already written into law or regulation; it excludes future policy changes, even where governments have announced intentions. Other drivers — technology cost declines, economics, demographics — are still in the model, but they only move the system as far as today’s policies allow. For that reason, I think the CPS is incredibly pessimistic about the speed of the transition (or, rather, that there is even a transition at all).</p><p>Running several scenarios is incredibly useful for understanding how trends would evolve under different conditions. The problem is that these are often misinterpreted or miscommunicated. They can take on a whole new world of their own.</p><p>If you have no understanding of the assumptions underlying any scenario, it’s impossible to know how to treat them. Only by looking under the hood can we start to judge whether they seem likely or not.</p><p>Here, I wanted to make the CPS a bit more transparent and show what the IEA assumes in some key areas, specifically the rollout of electric vehicles, and the speed of solar PV deployment.</p><div><hr></div><h1><strong>The electric car rollout stalls everywhere but China and Europe</strong></h1><p>Many countries in the world don’t have existing policies or legislation in place that would dramatically shift EV adoption rates. They often also lack charging infrastructure to absorb more electric cars without expanding it. The CPS assumes that neither changes.</p><p>That means the only regions where EV sales <em>do </em>grow are in the European Union and China. As you can see in the chart below, they achieve nearly 100% EV sales by 2035. But in every other region, EV sales basically stall at their current level.</p><p>What this means at a global level is that the market share for EVs increases from 25% today to 40% in 2035. But then this share falls a bit through to 2050, as most cars will be sold in countries where EVs have somehow been stuck at a multi-decade hiatus.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!YH46!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 424w, https://substackcdn.com/image/fetch/$s_!YH46!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 848w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1272w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png\" width=\"707\" height=\"462.2692307692308\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:952,&quot;width&quot;:1456,&quot;resizeWidth&quot;:707,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!YH46!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 424w, https://substackcdn.com/image/fetch/$s_!YH46!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 848w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1272w, https://substackcdn.com/image/fetch/$s_!YH46!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3bdfef0-16e9-4296-b038-71851f8031b2_1640x1072.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a><figcaption class=\"image-caption\">Source: International Energy Agency (2025). <a href=\"https://www.iea.org/reports/world-energy-outlook-2025\">World Energy Outlook 2025</a>.</figcaption></figure></div><p>Is this a reasonable assumption?</p><p>You be the judge. Take a look at the chart below, which shows the share of new cars that are electric in countries outside of the EU and China. Now imagine that those curves suddenly level off and never rise again. That’s what the CPS assumes.</p><p>I can’t tell you the pace of the global EV rollout. I also think that many countries will have temporary stalls in their EV sales for various reasons. Maybe we’ll see that in the US in the next few years. But given the historical rates of growth, the fact that electric cars continue to get better and cheaper, <em>and</em> national motivations to be free from the ups and downs of global oil markets, it seems implausible to me that all of these curves suddenly and permanently level off.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!EGy4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 424w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 848w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1272w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png\" width=\"701\" height=\"494.9368131868132\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1028,&quot;width&quot;:1456,&quot;resizeWidth&quot;:701,&quot;bytes&quot;:529590,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.sustainabilitybynumbers.com/i/179114194?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!EGy4!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 424w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 848w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1272w, https://substackcdn.com/image/fetch/$s_!EGy4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea8a510-93c2-4ddf-bb09-e84c460aced4_3400x2400.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>If EV sales stalled across most of the world, and efficiency improvements in petrol cars dramatically slowed (which the IEA also assumes), then you will get a result that says that oil demand will continue to increase all the way through to 2050.</p><p>The point is not that we should never consider what this scenario might look like. It’s useful and important to know what might happen to the EV rollout absent of new policies <em>or</em> other market and technological forces driving things forward. But it’s crucial for people to know what it is that they’re looking at. Clearly, judging by the headlines and broader discussion, this is not the case.</p><div><hr></div><h1><strong>Global deployment of solar PV stalls at 2024 levels</strong></h1><p>Moving from transport to the electricity grid, another interesting assumption in the Current Policies Scenario is that solar photovoltaic (PV) deployment stalls at its 2024 levels for more than a decade.</p><p>As it states:</p><p><em>“Solar PV and wind continue to expand, but they face mounting integration challenges in the CPS in the absence of additional government policies, which slow their deployment. Annual solar PV capacity additions average 540 GW to 2035, holding steady at roughly the 2024 level, and halting the trend that has seen deployment rise ten-fold from 2015 to 2024.”</em></p><p>To provide some context for what this looks like, I’ve plotted the IEA’s <a href=\"https://www.iea.org/data-and-statistics/data-tools/renewable-energy-progress-tracker\">historical data</a> on solar PV deployment (in red) and added a line that shows future deployments stalling at 540 GW through to 2035.<a class=\"footnote-anchor\" data-component-name=\"FootnoteAnchorToDOM\" id=\"footnote-anchor-1\" href=\"#footnote-1\" target=\"_self\">1</a></p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!rtOL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 424w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 848w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1272w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png\" width=\"695\" height=\"537.0020604395604\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1125,&quot;width&quot;:1456,&quot;resizeWidth&quot;:695,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!rtOL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 424w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 848w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1272w, https://substackcdn.com/image/fetch/$s_!rtOL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffb891b-77f8-46cb-84fa-13f0fa74333c_1600x1236.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>Does this trend also seem reasonable?</p><p>It does repeat the pattern of <a href=\"https://www.pv-magazine.com/2018/11/20/iea-versus-solar-pv-reality\">now-infamous</a> “expectations vs. reality” solar PV chart, which was first produced by <a href=\"https://www.aukehoekstra.nl/\">Auke Hoekstra</a>. The IEA’s “policy scenarios” projected a stalling of global PV deployment as far back as 2006, but actual growth has consistently exceeded these expectations year after year.</p><div class=\"captioned-image-container\"><figure><a class=\"image-link image2 is-viewable-img\" target=\"_blank\" href=\"https://substackcdn.com/image/fetch/$s_!Wljd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png\" data-component-name=\"Image2ToDOM\"><div class=\"image2-inset\"><picture><source type=\"image/webp\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 424w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 848w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1272w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1456w\" sizes=\"100vw\"><img src=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png\" width=\"551\" height=\"455\" data-attrs=\"{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:455,&quot;width&quot;:551,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}\" class=\"sizing-normal\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/$s_!Wljd!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 424w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 848w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1272w, https://substackcdn.com/image/fetch/$s_!Wljd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e0ee2b1-5088-4038-a89e-f2f187cfdfbd_551x455.png 1456w\" sizes=\"100vw\" loading=\"lazy\"></picture><div class=\"image-link-expand\"><div class=\"pencraft pc-display-flex pc-gap-8 pc-reset\"><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container restack-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-refresh-cw\"><path d=\"M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8\"></path><path d=\"M21 3v5h-5\"></path><path d=\"M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16\"></path><path d=\"M8 16H3v5\"></path></svg></button><button tabindex=\"0\" type=\"button\" class=\"pencraft pc-reset pencraft icon-container view-image\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"lucide lucide-maximize2 lucide-maximize-2\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" x2=\"14\" y1=\"3\" y2=\"10\"></line><line x1=\"3\" x2=\"10\" y1=\"21\" y2=\"14\"></line></svg></button></div></div></div></a></figure></div><p>I think the assumption that solar PV will top out at 2024 levels for more than a decade is overly conservative and pessimistic. I don’t think this will happen in the way it’s portrayed in the chart.</p><p>However, this assumption is not <em>quite</em> as bewildering as the one on electric vehicles. There is a reasonable discussion to be had about <em>when</em> global deployment rates start to slow. Solar deployment has undergone several “doublings” now. That curve probably doesn’t have many left in it. When China’s rates start to slow — which they eventually will — this will have a big impact on the global total. Even if deployment is going strong and continuing to rise in other low-to middle-income countries, they’re too small to pick up the “slack” from China’s slowed rates.</p><p>I still think it’s unlikely that we’re at peak solar PV deployment globally. Some might disagree.</p><p>That’s fine, and that’s the point of laying out some of the crucial underlying assumptions of these scenarios. You can judge what you think is realistic or not. But without this transparency, many are left with headlines like “<a href=\"https://www.offshore-technology.com/news/iea-oil-and-gas-consumption-prediction/\">IEA predicts increase in oil and gas consumption until 2050</a>”. This is <em>not</em> what the IEA predicts, because it does not provide predictions at all.</p><div><hr></div><p class=\"button-wrapper\" data-attrs=\"{&quot;url&quot;:&quot;https://www.sustainabilitybynumbers.com/subscribe?&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}\" data-component-name=\"ButtonCreateButton\"><a class=\"button primary\" href=\"https://www.sustainabilitybynumbers.com/subscribe?\"><span>Subscribe now</span></a></p><div class=\"footnote\" data-component-name=\"FootnoteToDOM\"><a id=\"footnote-1\" href=\"#footnote-anchor-1\" class=\"footnote-number\" contenteditable=\"false\" target=\"_self\">1</a><div class=\"footnote-content\"><p>I’ve summed the historical data for “PV distributed systems” and “PV utility-scale systems” for each year.<br><br>This has been unified by the IEA to direct current (DC).</p><p>https://www.iea.org/data-and-statistics/data-tools/renewable-energy-progress-tracker</p><p></p></div></div>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48ef74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
